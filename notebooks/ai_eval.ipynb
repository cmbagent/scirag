{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13d7196b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed GOOGLE_API_KEY from environment\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"gemini.json\"\n",
    "# Remove the API key if it exists\n",
    "if \"GOOGLE_API_KEY\" in os.environ:\n",
    "    del os.environ[\"GOOGLE_API_KEY\"]\n",
    "    print(\"Removed GOOGLE_API_KEY from environment\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb188fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/pybtex/plugin/__init__.py:26: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "from scirag import SingleRAGEvaluationSystem,GeminiEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "886f932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffcea05",
   "metadata": {},
   "source": [
    "# Cost Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5d6fe449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import os\n",
    "import glob\n",
    "from typing import List, Dict, Union\n",
    "\n",
    "def count_tokens_in_markdown_files(file_paths: Union[str, List[str]], encoding_name: str = \"cl100k_base\") -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Count tokens in markdown files using tiktoken.\n",
    "    \n",
    "    Args:\n",
    "        file_paths: Either a glob pattern (str) or list of file paths\n",
    "        encoding_name: Tiktoken encoding to use (default: \"cl100k_base\" for GPT-4)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with file paths as keys and token counts as values\n",
    "    \"\"\"\n",
    "    # Handle glob pattern or list of paths\n",
    "    if isinstance(file_paths, str):\n",
    "        # It's a glob pattern\n",
    "        file_list = glob.glob(file_paths)\n",
    "        if not file_list:\n",
    "            print(f\"No files found matching pattern: {file_paths}\")\n",
    "            return {}\n",
    "    else:\n",
    "        # It's already a list\n",
    "        file_list = file_paths\n",
    "    # Initialize the encoding\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    \n",
    "    token_counts = {}\n",
    "    total_tokens = 0\n",
    "    \n",
    "    for file_path in file_list:\n",
    "        try:\n",
    "            # Read the markdown file\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "            \n",
    "            # Count tokens\n",
    "            tokens = encoding.encode(content)\n",
    "            token_count = len(tokens)\n",
    "            \n",
    "            # Store result\n",
    "            filename = os.path.basename(file_path)\n",
    "            token_counts[filename] = token_count\n",
    "            total_tokens += token_count\n",
    "            \n",
    "            print(f\"{filename}: {token_count:,} tokens\")\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: File not found - {file_path}\")\n",
    "            token_counts[os.path.basename(file_path)] = 0\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file_path}: {e}\")\n",
    "            token_counts[os.path.basename(file_path)] = 0\n",
    "    \n",
    "    # Add total\n",
    "    token_counts['TOTAL'] = total_tokens\n",
    "    print(f\"\\nTotal across all files: {total_tokens:,} tokens\")\n",
    "    \n",
    "    return token_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4d390c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2503.14454v1.md: 111,530 tokens\n",
      "2010.00619v2.md: 42,730 tokens\n",
      "2201.02202v1.md: 24,819 tokens\n",
      "1807.06209v4.md: 133,523 tokens\n",
      "1604.01424v3.md: 62,766 tokens\n",
      "\n",
      "Total across all files: 375,368 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'2503.14454v1.md': 111530,\n",
       " '2010.00619v2.md': 42730,\n",
       " '2201.02202v1.md': 24819,\n",
       " '1807.06209v4.md': 133523,\n",
       " '1604.01424v3.md': 62766,\n",
       " 'TOTAL': 375368}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_tokens_in_markdown_files(\"../markdowns/*.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e485a504",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vertex AI embedding ->$0.004692\n",
    "# text-embedding-3-large ->$0.048798\n",
    "#gemini-embedding-001-> $0.004692"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dadcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paperqa2 0.0045+$0.048798\n",
    "\n",
    "#Modified PaperQA2 0.1604+$0.048798\n",
    "\n",
    "#OpenAI PDF/MD 0.03859+0.048798\n",
    "\n",
    "#Vertex MD\n",
    "\n",
    "#perplexity\n",
    "\n",
    "#hybrid\n",
    "\n",
    "#gemini\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f4abea",
   "metadata": {},
   "source": [
    "# Perplexity Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68c9a292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_question(qids, responses_df):\n",
    "    \"\"\"\n",
    "    Evaluate multiple questions from a pandas DataFrame\n",
    "    \n",
    "    Args:\n",
    "        qids: List of question IDs to evaluate\n",
    "        responses_df: pandas DataFrame with columns: question_id, question, answer, ideal_solution\n",
    "        gemini_evaluator: Initialized evaluator instance\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary mapping question IDs to evaluation results\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    print(f\"Evaluating {len(qids)} questions...\")\n",
    "    print(\"=\" * 50)\n",
    "    gemini_evaluator=GeminiEvaluator()\n",
    "    \n",
    "    for i, qid in enumerate(qids, 1):\n",
    "        print(f\"\\n[{i}/{len(qids)}] Evaluating Question ID: {qid}\")\n",
    "        \n",
    "        try:\n",
    "            # Filter DataFrame for this question ID\n",
    "            question_rows = responses_df[responses_df[\"question_id\"] == qid]\n",
    "            \n",
    "            # Check if question exists\n",
    "            if question_rows.empty:\n",
    "                print(f\"  Question ID {qid} not found in DataFrame\")\n",
    "                results[qid] = {\n",
    "                    \"eval_accuracy_score\": None,\n",
    "                    \"eval_rationale\": f\"Question ID {qid} not found\",\n",
    "                    \"eval_successful\": False,\n",
    "                    \"eval_error\": \"Question not found\"\n",
    "                }\n",
    "                continue\n",
    "            \n",
    "            # Get the first (should be only) row\n",
    "            row = question_rows.iloc[0]\n",
    "            \n",
    "            # Check for required columns and non-null values\n",
    "            required_cols = [\"question\", \"answer\", \"ideal_solution\"]\n",
    "            missing_cols = [col for col in required_cols if col not in responses_df.columns]\n",
    "            \n",
    "            if missing_cols:\n",
    "                print(f\"  ❌ Missing columns: {missing_cols}\")\n",
    "                results[qid] = {\n",
    "                    \"eval_accuracy_score\": None,\n",
    "                    \"eval_rationale\": f\"Missing columns: {missing_cols}\",\n",
    "                    \"eval_successful\": False,\n",
    "                    \"eval_error\": f\"Missing columns: {missing_cols}\"\n",
    "                }\n",
    "                continue\n",
    "            \n",
    "            # Check for null values\n",
    "            null_fields = [col for col in required_cols if pd.isna(row[col])]\n",
    "            if null_fields:\n",
    "                print(f\"  ❌ Null values in: {null_fields}\")\n",
    "                results[qid] = {\n",
    "                    \"eval_accuracy_score\": None,\n",
    "                    \"eval_rationale\": f\"Null values in: {null_fields}\",\n",
    "                    \"eval_successful\": False,\n",
    "                    \"eval_error\": f\"Null values: {null_fields}\"\n",
    "                }\n",
    "                continue\n",
    "            \n",
    "            # Perform evaluation\n",
    "            result = gemini_evaluator.evaluate_single_response(\n",
    "                question=row[\"question\"],\n",
    "                generated_answer=row[\"answer\"],\n",
    "                ideal_answer=row[\"ideal_solution\"],\n",
    "            )\n",
    "            \n",
    "            # Store result\n",
    "            results[qid] = result\n",
    "            \n",
    "            # Print progress\n",
    "            if result['eval_successful']:\n",
    "                print(f\"  Score: {result['eval_accuracy_score']}/100\")\n",
    "                print(f\"  Rationale: {result['eval_rationale'][:100]}...\")\n",
    "            else:\n",
    "                print(f\"  Failed: {result['eval_error']}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  Exception occurred: {str(e)}\")\n",
    "            results[qid] = {\n",
    "                \"eval_accuracy_score\": None,\n",
    "                \"eval_rationale\": f\"Exception: {str(e)}\",\n",
    "                \"eval_successful\": False,\n",
    "                \"eval_error\": str(e)\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ab1cde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity=pd.read_pickle(\"results/perplexity_results_final.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd67fb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: GOOGLE_API_KEY found in environment. Removing to use service account.\n",
      "[Init] Initialized gemini-2.5-pro-preview-06-05 successfully with service account: gemini.json\n",
      "Initialized evaluation system with gemini backend\n",
      "Using model: gemini-2.5-pro-preview-06-05\n"
     ]
    }
   ],
   "source": [
    "gemini_evaluator = SingleRAGEvaluationSystem(evaluator_backend=\"gemini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4614b653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EVALUATING: Perplexity (using gemini backend)\n",
      "============================================================\n",
      "All required columns found\n",
      "Available columns: ['question_id', 'question', 'response', 'answer', 'sources', 'ideal_solution', 'processing_time', 'success', 'error', 'embedding_system']\n",
      "Filtering by success column: 105 successful out of 105 total\n",
      "Rate limit status: 0/150 requests, 0/2000000 tokens\n",
      "\n",
      "Evaluating 1/105 - Question ID: 1\n",
      "Accuracy:0\n",
      "  Time: 11.27s\n",
      "\n",
      "Evaluating 2/105 - Question ID: 2\n",
      "Accuracy:100\n",
      "  Time: 15.74s\n",
      "\n",
      "Evaluating 3/105 - Question ID: 3\n",
      "Accuracy:0\n",
      "  Time: 9.19s\n",
      "\n",
      "Evaluating 4/105 - Question ID: 4\n",
      "Accuracy:0\n",
      "  Time: 11.03s\n",
      "\n",
      "Evaluating 5/105 - Question ID: 5\n",
      "Accuracy:100\n",
      "  Time: 11.78s\n",
      "\n",
      "Evaluating 6/105 - Question ID: 6\n",
      "  ✗ Failed: Unknown error after 1 attempts: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.\n",
      "\n",
      "Evaluating 7/105 - Question ID: 7\n",
      "Accuracy:0\n",
      "  Time: 15.05s\n",
      "\n",
      "Evaluating 8/105 - Question ID: 8\n",
      "Accuracy:0\n",
      "  Time: 20.11s\n",
      "\n",
      "Evaluating 9/105 - Question ID: 9\n",
      "Accuracy:0\n",
      "  Time: 16.31s\n",
      "\n",
      "Evaluating 10/105 - Question ID: 10\n",
      "Accuracy:100\n",
      "  Time: 12.63s\n",
      "\n",
      "Evaluating 11/105 - Question ID: 11\n",
      "Accuracy:0\n",
      "  Time: 9.72s\n",
      "\n",
      "Evaluating 12/105 - Question ID: 12\n",
      "Accuracy:0\n",
      "  Time: 20.32s\n",
      "\n",
      "Evaluating 13/105 - Question ID: 13\n",
      "Accuracy:100\n",
      "  Time: 15.22s\n",
      "\n",
      "Evaluating 14/105 - Question ID: 14\n",
      "  ✗ Failed: Unknown error after 1 attempts: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.\n",
      "\n",
      "Evaluating 15/105 - Question ID: 15\n",
      "Accuracy:100\n",
      "  Time: 9.62s\n",
      "\n",
      "Evaluating 16/105 - Question ID: 16\n",
      "Accuracy:100\n",
      "  Time: 22.10s\n",
      "\n",
      "Evaluating 17/105 - Question ID: 17\n",
      "Accuracy:100\n",
      "  Time: 9.55s\n",
      "\n",
      "Evaluating 18/105 - Question ID: 18\n",
      "Failed to parse Gemini JSON response: Unterminated string starting at: line 3 column 16 (char 42)\n",
      "Raw response: {\n",
      "  \"accuracy_score\": 100,\n",
      "  \"rationale\": \"The generated answer provides the value for the optical depth as \\\\(\\\\tau = 0.054 \\\\pm 0.007\\\\). This is the standard, commonly cited result from the main Planck 2018 cosmological parameter paper (specifically, from the abstract of 'Planck 2018 results. VI....\n",
      "  ✗ Failed: JSON parse error: Unterminated string starting at: line 3 column 16 (char 42)\n",
      "\n",
      "Evaluating 19/105 - Question ID: 19\n",
      "Accuracy:100\n",
      "  Time: 11.16s\n",
      "\n",
      "Evaluating 20/105 - Question ID: 20\n",
      "Accuracy:100\n",
      "  Time: 11.71s\n",
      "\n",
      "Evaluating 21/105 - Question ID: 21\n",
      "Accuracy:0\n",
      "  Time: 14.12s\n",
      "\n",
      "Evaluating 22/105 - Question ID: 22\n",
      "Accuracy:0\n",
      "  Time: 22.00s\n",
      "\n",
      "Evaluating 23/105 - Question ID: 23\n",
      "Accuracy:0\n",
      "  Time: 13.09s\n",
      "\n",
      "Evaluating 24/105 - Question ID: 24\n",
      "Accuracy:0\n",
      "  Time: 12.11s\n",
      "\n",
      "Evaluating 25/105 - Question ID: 25\n",
      "Accuracy:100\n",
      "  Time: 21.23s\n",
      "\n",
      "Evaluating 26/105 - Question ID: 26\n",
      "Accuracy:0\n",
      "  Time: 11.48s\n",
      "\n",
      "Evaluating 27/105 - Question ID: 27\n",
      "Accuracy:0\n",
      "  Time: 8.27s\n",
      "\n",
      "Evaluating 28/105 - Question ID: 28\n",
      "Accuracy:100\n",
      "  Time: 13.95s\n",
      "\n",
      "Evaluating 29/105 - Question ID: 29\n",
      "Accuracy:0\n",
      "  Time: 20.00s\n",
      "\n",
      "Evaluating 30/105 - Question ID: 30\n",
      "Accuracy:100\n",
      "  Time: 9.20s\n",
      "\n",
      "Evaluating 31/105 - Question ID: 31\n",
      "Accuracy:100\n",
      "  Time: 13.61s\n",
      "\n",
      "Evaluating 32/105 - Question ID: 32\n",
      "Accuracy:0\n",
      "  Time: 9.11s\n",
      "\n",
      "Evaluating 33/105 - Question ID: 33\n",
      "Accuracy:100\n",
      "  Time: 11.77s\n",
      "\n",
      "Evaluating 34/105 - Question ID: 34\n",
      "Accuracy:0\n",
      "  Time: 10.23s\n",
      "\n",
      "Evaluating 35/105 - Question ID: 35\n",
      "Accuracy:0\n",
      "  Time: 9.22s\n",
      "\n",
      "Evaluating 36/105 - Question ID: 36\n",
      "Accuracy:0\n",
      "  Time: 16.03s\n",
      "\n",
      "Evaluating 37/105 - Question ID: 37\n",
      "Accuracy:0\n",
      "  Time: 17.05s\n",
      "\n",
      "Evaluating 38/105 - Question ID: 38\n",
      "Accuracy:0\n",
      "  Time: 9.20s\n",
      "\n",
      "Evaluating 39/105 - Question ID: 39\n",
      "Accuracy:0\n",
      "  Time: 8.76s\n",
      "\n",
      "Evaluating 40/105 - Question ID: 40\n",
      "Accuracy:0\n",
      "  Time: 10.77s\n",
      "\n",
      "Evaluating 41/105 - Question ID: 41\n",
      "  ✗ Failed: Unknown error after 1 attempts: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.\n",
      "\n",
      "Evaluating 42/105 - Question ID: 42\n",
      "Accuracy:0\n",
      "  Time: 8.71s\n",
      "\n",
      "Evaluating 43/105 - Question ID: 43\n",
      "Accuracy:0\n",
      "  Time: 17.40s\n",
      "\n",
      "Evaluating 44/105 - Question ID: 44\n",
      "Accuracy:0\n",
      "  Time: 8.16s\n",
      "\n",
      "Evaluating 45/105 - Question ID: 45\n",
      "Accuracy:0\n",
      "  Time: 15.52s\n",
      "\n",
      "Evaluating 46/105 - Question ID: 46\n",
      "Accuracy:0\n",
      "  Time: 7.20s\n",
      "\n",
      "Evaluating 47/105 - Question ID: 47\n",
      "Accuracy:0\n",
      "  Time: 9.66s\n",
      "\n",
      "Evaluating 48/105 - Question ID: 48\n",
      "Accuracy:0\n",
      "  Time: 10.91s\n",
      "\n",
      "Evaluating 49/105 - Question ID: 49\n",
      "Accuracy:0\n",
      "  Time: 8.41s\n",
      "\n",
      "Evaluating 50/105 - Question ID: 50\n",
      "Accuracy:0\n",
      "  Time: 11.85s\n",
      "\n",
      "Evaluating 51/105 - Question ID: 51\n",
      "Accuracy:0\n",
      "  Time: 13.82s\n",
      "\n",
      "Evaluating 52/105 - Question ID: 52\n",
      "Accuracy:100\n",
      "  Time: 12.54s\n",
      "\n",
      "Evaluating 53/105 - Question ID: 53\n",
      "Accuracy:0\n",
      "  Time: 12.71s\n",
      "\n",
      "Evaluating 54/105 - Question ID: 54\n",
      "Accuracy:0\n",
      "  Time: 10.28s\n",
      "\n",
      "Evaluating 55/105 - Question ID: 55\n",
      "Accuracy:0\n",
      "  Time: 13.50s\n",
      "\n",
      "Evaluating 56/105 - Question ID: 56\n",
      "Accuracy:100\n",
      "  Time: 11.61s\n",
      "\n",
      "Evaluating 57/105 - Question ID: 57\n",
      "Accuracy:100\n",
      "  Time: 13.86s\n",
      "\n",
      "Evaluating 58/105 - Question ID: 58\n",
      "Accuracy:0\n",
      "  Time: 11.29s\n",
      "\n",
      "Evaluating 59/105 - Question ID: 59\n",
      "Accuracy:0\n",
      "  Time: 13.31s\n",
      "\n",
      "Evaluating 60/105 - Question ID: 60\n",
      "Accuracy:0\n",
      "  Time: 16.88s\n",
      "\n",
      "Evaluating 61/105 - Question ID: 61\n",
      "Accuracy:0\n",
      "  Time: 11.31s\n",
      "\n",
      "Evaluating 62/105 - Question ID: 62\n",
      "Accuracy:0\n",
      "  Time: 19.41s\n",
      "\n",
      "Evaluating 63/105 - Question ID: 63\n",
      "Accuracy:0\n",
      "  Time: 16.11s\n",
      "\n",
      "Evaluating 64/105 - Question ID: 64\n",
      "Accuracy:100\n",
      "  Time: 8.52s\n",
      "\n",
      "Evaluating 65/105 - Question ID: 65\n",
      "Accuracy:0\n",
      "  Time: 19.80s\n",
      "\n",
      "Evaluating 66/105 - Question ID: 66\n",
      "Accuracy:100\n",
      "  Time: 12.70s\n",
      "\n",
      "Evaluating 67/105 - Question ID: 67\n",
      "Accuracy:0\n",
      "  Time: 7.07s\n",
      "\n",
      "Evaluating 68/105 - Question ID: 68\n",
      "Accuracy:0\n",
      "  Time: 9.84s\n",
      "\n",
      "Evaluating 69/105 - Question ID: 69\n",
      "  ✗ Failed: Unknown error after 1 attempts: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.\n",
      "\n",
      "Evaluating 70/105 - Question ID: 70\n",
      "Accuracy:0\n",
      "  Time: 11.07s\n",
      "\n",
      "Evaluating 71/105 - Question ID: 71\n",
      "  ✗ Failed: Unknown error after 1 attempts: Empty response received from Gemini\n",
      "\n",
      "Evaluating 72/105 - Question ID: 72\n",
      "Accuracy:0\n",
      "  Time: 8.42s\n",
      "\n",
      "Evaluating 73/105 - Question ID: 73\n",
      "Accuracy:0\n",
      "  Time: 7.87s\n",
      "\n",
      "Evaluating 74/105 - Question ID: 74\n",
      "Accuracy:100\n",
      "  Time: 21.19s\n",
      "\n",
      "Evaluating 75/105 - Question ID: 75\n",
      "Accuracy:0\n",
      "  Time: 13.09s\n",
      "\n",
      "Evaluating 76/105 - Question ID: 76\n",
      "Accuracy:100\n",
      "  Time: 18.46s\n",
      "\n",
      "Evaluating 77/105 - Question ID: 77\n",
      "Accuracy:0\n",
      "  Time: 14.22s\n",
      "\n",
      "Evaluating 78/105 - Question ID: 78\n",
      "Accuracy:0\n",
      "  Time: 18.33s\n",
      "\n",
      "Evaluating 79/105 - Question ID: 79\n",
      "Accuracy:0\n",
      "  Time: 9.01s\n",
      "\n",
      "Evaluating 80/105 - Question ID: 80\n",
      "Accuracy:0\n",
      "  Time: 11.58s\n",
      "\n",
      "Evaluating 81/105 - Question ID: 81\n",
      "  ✗ Failed: Unknown error after 1 attempts: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.\n",
      "\n",
      "Evaluating 82/105 - Question ID: 82\n",
      "Accuracy:0\n",
      "  Time: 14.74s\n",
      "\n",
      "Evaluating 83/105 - Question ID: 83\n",
      "Accuracy:100\n",
      "  Time: 6.76s\n",
      "\n",
      "Evaluating 84/105 - Question ID: 84\n",
      "Accuracy:100\n",
      "  Time: 14.79s\n",
      "\n",
      "Evaluating 85/105 - Question ID: 85\n",
      "Accuracy:0\n",
      "  Time: 12.73s\n",
      "\n",
      "Evaluating 86/105 - Question ID: 86\n",
      "Accuracy:0\n",
      "  Time: 9.91s\n",
      "\n",
      "Evaluating 87/105 - Question ID: 87\n",
      "Accuracy:100\n",
      "  Time: 7.83s\n",
      "\n",
      "Evaluating 88/105 - Question ID: 88\n",
      "Accuracy:100\n",
      "  Time: 13.49s\n",
      "\n",
      "Evaluating 89/105 - Question ID: 89\n",
      "Accuracy:0\n",
      "  Time: 9.76s\n",
      "\n",
      "Evaluating 90/105 - Question ID: 90\n",
      "Accuracy:100\n",
      "  Time: 11.96s\n",
      "\n",
      "Evaluating 91/105 - Question ID: 91\n",
      "Accuracy:0\n",
      "  Time: 9.71s\n",
      "\n",
      "Evaluating 92/105 - Question ID: 92\n",
      "Accuracy:0\n",
      "  Time: 9.87s\n",
      "\n",
      "Evaluating 93/105 - Question ID: 93\n",
      "Accuracy:0\n",
      "  Time: 17.66s\n",
      "\n",
      "Evaluating 94/105 - Question ID: 94\n",
      "Accuracy:100\n",
      "  Time: 12.29s\n",
      "\n",
      "Evaluating 95/105 - Question ID: 95\n",
      "Accuracy:0\n",
      "  Time: 15.55s\n",
      "\n",
      "Evaluating 96/105 - Question ID: 96\n",
      "Accuracy:100\n",
      "  Time: 14.30s\n",
      "\n",
      "Evaluating 97/105 - Question ID: 97\n",
      "Accuracy:100\n",
      "  Time: 11.82s\n",
      "\n",
      "Evaluating 98/105 - Question ID: 98\n",
      "Accuracy:0\n",
      "  Time: 12.49s\n",
      "\n",
      "Evaluating 99/105 - Question ID: 99\n",
      "Accuracy:0\n",
      "  Time: 11.15s\n",
      "\n",
      "Evaluating 100/105 - Question ID: 100\n",
      "Accuracy:0\n",
      "  Time: 11.22s\n",
      "\n",
      "Evaluating 101/105 - Question ID: 101\n",
      "Accuracy:100\n",
      "  Time: 20.38s\n",
      "\n",
      "Evaluating 102/105 - Question ID: 102\n",
      "Accuracy:0\n",
      "  Time: 11.60s\n",
      "\n",
      "Evaluating 103/105 - Question ID: 103\n",
      "Accuracy:0\n",
      "  Time: 14.95s\n",
      "\n",
      "Evaluating 104/105 - Question ID: 104\n",
      "Accuracy:100\n",
      "  Time: 17.82s\n",
      "\n",
      "Evaluating 105/105 - Question ID: 105\n",
      "Accuracy:0\n",
      "  Time: 17.09s\n",
      "\n",
      "============================================================\n",
      "EVALUATION COMPLETE: Perplexity\n",
      "============================================================\n",
      "Backend: gemini\n",
      "Total evaluation time: 1435.66 seconds\n",
      "Successful evaluations: 98/105\n",
      "Success rate: 93.3%\n",
      "\n",
      "Average Scores:\n",
      "  Accuracy: 31.63\n",
      "\n",
      "Final rate limit usage: 1/150 requests, 207/2000000 tokens\n",
      "\n",
      "Results saved to: rag_evaluation_results_gemini/perplexity_evaluated_20250608_143121.csv\n"
     ]
    }
   ],
   "source": [
    "perplexity_evaluated = gemini_evaluator.evaluate_single_dataframe(\n",
    "    df=perplexity,\n",
    "    system_name=\"Perplexity\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "697b6325",
   "metadata": {},
   "outputs": [],
   "source": [
    "qids=[6,14,18,41,69,71,81]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09208ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 7 questions...\n",
      "==================================================\n",
      "Warning: GOOGLE_API_KEY found in environment. Removing to use service account.\n",
      "[Init] Initialized gemini-2.5-pro-preview-06-05 successfully with service account: gemini.json\n",
      "\n",
      "[1/7] Evaluating Question ID: 6\n",
      "[Backoff] Attempt 1/3 failed. Unknown error: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.\n",
      "[Backoff] Sleeping for 24.6 seconds (base: 30s, multiplier: 2.0)\n",
      "[Backoff] Attempt 2/3 failed. Unknown error: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.\n",
      "[Backoff] Sleeping for 70.7 seconds (base: 30s, multiplier: 2.0)\n",
      "  Score: 0/100\n",
      "  Rationale: The generated answer provides a value for a different, though related, parameter. The question asks ...\n",
      "\n",
      "[2/7] Evaluating Question ID: 14\n",
      "  Score: 0/100\n",
      "  Rationale: The generated answer does not contain the core factual content from the ideal answer. The ideal answ...\n",
      "\n",
      "[3/7] Evaluating Question ID: 18\n",
      "Failed to parse Gemini JSON response: Unterminated string starting at: line 3 column 16 (char 42)\n",
      "Raw response: {\n",
      "  \"accuracy_score\": 100,\n",
      "  \"rationale\": \"The generated answer provides the value for the optical depth as 0.054 ± 0.007. The ideal answer is 0.0506 ± 0.0086. Both of these values are valid results from the Planck 2018 data release, corresponding to slightly different data combinations and likeliho...\n",
      "  Failed: JSON parse error: Unterminated string starting at: line 3 column 16 (char 42)\n",
      "\n",
      "[4/7] Evaluating Question ID: 41\n",
      "  Score: 0/100\n",
      "  Rationale: The generated answer is factually incorrect. It lists the wrong parameters for the CAMELS SIMBA EX s...\n",
      "\n",
      "[5/7] Evaluating Question ID: 69\n",
      "[Backoff] Attempt 1/3 failed. Unknown error: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.\n",
      "[Backoff] Sleeping for 30.9 seconds (base: 30s, multiplier: 2.0)\n",
      "  Score: 0/100\n",
      "  Rationale: The generated answer is fundamentally incorrect because it contradicts the ideal answer's core scien...\n",
      "\n",
      "[6/7] Evaluating Question ID: 71\n",
      "  Score: 100/100\n",
      "  Rationale: The generated answer correctly identifies the core scientific concepts and consequences of not corre...\n",
      "\n",
      "[7/7] Evaluating Question ID: 81\n",
      "[Backoff] Attempt 1/3 failed. Unknown error: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.\n",
      "[Backoff] Sleeping for 30.4 seconds (base: 30s, multiplier: 2.0)\n",
      "[Backoff] Attempt 2/3 failed. Unknown error: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.\n",
      "[Backoff] Sleeping for 48.5 seconds (base: 30s, multiplier: 2.0)\n",
      "Failed to parse Gemini JSON response: Unterminated string starting at: line 3 column 3 (char 27)\n",
      "Raw response: {\n",
      "  \"accuracy_score\": 0,\n",
      "  \"ration...\n",
      "  Failed: JSON parse error: Unterminated string starting at: line 3 column 3 (char 27)\n"
     ]
    }
   ],
   "source": [
    "missing_question(qids, perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d29813c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.426095238095236"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(98*31.63+0+0+100+0+0+100+0)/105"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064e84b3",
   "metadata": {},
   "source": [
    "# Vertex RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d05b09dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Vetex_RAG=pd.read_pickle(\"results/vertexai_rag_results_final.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03c63e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EVALUATING: Gemini_embedding (using gemini backend)\n",
      "============================================================\n",
      "All required columns found\n",
      "Available columns: ['question_id', 'question', 'response', 'answer', 'sources', 'ideal_solution', 'processing_time', 'success', 'error', 'embedding_system']\n",
      "Filtering by success column: 105 successful out of 105 total\n",
      "Rate limit status: 1/150 requests, 207/2000000 tokens\n",
      "\n",
      "Evaluating 1/105 - Question ID: 1\n",
      "Accuracy:100\n",
      "  Time: 7.54s\n",
      "\n",
      "Evaluating 2/105 - Question ID: 2\n",
      "Accuracy:100\n",
      "  Time: 11.56s\n",
      "\n",
      "Evaluating 3/105 - Question ID: 3\n",
      "Accuracy:100\n",
      "  Time: 9.42s\n",
      "\n",
      "Evaluating 4/105 - Question ID: 4\n",
      "Accuracy:100\n",
      "  Time: 12.28s\n",
      "\n",
      "Evaluating 5/105 - Question ID: 5\n",
      "Accuracy:100\n",
      "  Time: 9.01s\n",
      "\n",
      "Evaluating 6/105 - Question ID: 6\n",
      "Accuracy:100\n",
      "  Time: 9.11s\n",
      "\n",
      "Evaluating 7/105 - Question ID: 7\n",
      "Accuracy:0\n",
      "  Time: 8.91s\n",
      "\n",
      "Evaluating 8/105 - Question ID: 8\n",
      "Accuracy:0\n",
      "  Time: 15.97s\n",
      "\n",
      "Evaluating 9/105 - Question ID: 9\n",
      "Accuracy:100\n",
      "  Time: 14.44s\n",
      "\n",
      "Evaluating 10/105 - Question ID: 10\n",
      "Accuracy:100\n",
      "  Time: 9.23s\n",
      "\n",
      "Evaluating 11/105 - Question ID: 11\n",
      "Accuracy:100\n",
      "  Time: 7.50s\n",
      "\n",
      "Evaluating 12/105 - Question ID: 12\n",
      "Accuracy:100\n",
      "  Time: 9.10s\n",
      "\n",
      "Evaluating 13/105 - Question ID: 13\n",
      "Accuracy:100\n",
      "  Time: 10.85s\n",
      "\n",
      "Evaluating 14/105 - Question ID: 14\n",
      "Accuracy:100\n",
      "  Time: 12.00s\n",
      "\n",
      "Evaluating 15/105 - Question ID: 15\n",
      "Accuracy:100\n",
      "  Time: 7.93s\n",
      "\n",
      "Evaluating 16/105 - Question ID: 16\n",
      "Accuracy:100\n",
      "  Time: 11.13s\n",
      "\n",
      "Evaluating 17/105 - Question ID: 17\n",
      "Accuracy:100\n",
      "  Time: 9.87s\n",
      "\n",
      "Evaluating 18/105 - Question ID: 18\n",
      "Accuracy:100\n",
      "  Time: 16.17s\n",
      "\n",
      "Evaluating 19/105 - Question ID: 19\n",
      "Accuracy:100\n",
      "  Time: 9.95s\n",
      "\n",
      "Evaluating 20/105 - Question ID: 20\n",
      "Accuracy:100\n",
      "  Time: 12.41s\n",
      "\n",
      "Evaluating 21/105 - Question ID: 21\n",
      "Accuracy:100\n",
      "  Time: 11.94s\n",
      "\n",
      "Evaluating 22/105 - Question ID: 22\n",
      "Accuracy:0\n",
      "  Time: 15.56s\n",
      "\n",
      "Evaluating 23/105 - Question ID: 23\n",
      "Accuracy:100\n",
      "  Time: 8.49s\n",
      "\n",
      "Evaluating 24/105 - Question ID: 24\n",
      "Accuracy:100\n",
      "  Time: 7.17s\n",
      "\n",
      "Evaluating 25/105 - Question ID: 25\n",
      "Accuracy:100\n",
      "  Time: 8.03s\n",
      "\n",
      "Evaluating 26/105 - Question ID: 26\n",
      "Accuracy:100\n",
      "  Time: 13.68s\n",
      "\n",
      "Evaluating 27/105 - Question ID: 27\n",
      "Accuracy:100\n",
      "  Time: 11.37s\n",
      "\n",
      "Evaluating 28/105 - Question ID: 28\n",
      "Accuracy:0\n",
      "  Time: 24.09s\n",
      "\n",
      "Evaluating 29/105 - Question ID: 29\n",
      "Accuracy:100\n",
      "  Time: 12.53s\n",
      "\n",
      "Evaluating 30/105 - Question ID: 30\n",
      "Accuracy:100\n",
      "  Time: 12.14s\n",
      "\n",
      "Evaluating 31/105 - Question ID: 31\n",
      "Accuracy:100\n",
      "  Time: 7.86s\n",
      "\n",
      "Evaluating 32/105 - Question ID: 32\n",
      "Accuracy:100\n",
      "  Time: 14.23s\n",
      "\n",
      "Evaluating 33/105 - Question ID: 33\n",
      "Accuracy:100\n",
      "  Time: 9.32s\n",
      "\n",
      "Evaluating 34/105 - Question ID: 34\n",
      "Accuracy:0\n",
      "  Time: 19.11s\n",
      "\n",
      "Evaluating 35/105 - Question ID: 35\n",
      "Accuracy:100\n",
      "  Time: 8.11s\n",
      "\n",
      "Evaluating 36/105 - Question ID: 36\n",
      "Accuracy:100\n",
      "  Time: 10.55s\n",
      "\n",
      "Evaluating 37/105 - Question ID: 37\n",
      "Accuracy:100\n",
      "  Time: 10.54s\n",
      "\n",
      "Evaluating 38/105 - Question ID: 38\n",
      "Accuracy:100\n",
      "  Time: 9.01s\n",
      "\n",
      "Evaluating 39/105 - Question ID: 39\n",
      "Accuracy:100\n",
      "  Time: 9.79s\n",
      "\n",
      "Evaluating 40/105 - Question ID: 40\n",
      "Accuracy:100\n",
      "  Time: 7.41s\n",
      "\n",
      "Evaluating 41/105 - Question ID: 41\n",
      "Accuracy:100\n",
      "  Time: 8.29s\n",
      "\n",
      "Evaluating 42/105 - Question ID: 42\n",
      "Accuracy:100\n",
      "  Time: 10.14s\n",
      "\n",
      "Evaluating 43/105 - Question ID: 43\n",
      "Accuracy:100\n",
      "  Time: 11.18s\n",
      "\n",
      "Evaluating 44/105 - Question ID: 44\n",
      "Accuracy:100\n",
      "  Time: 13.29s\n",
      "\n",
      "Evaluating 45/105 - Question ID: 45\n",
      "Accuracy:100\n",
      "  Time: 14.74s\n",
      "\n",
      "Evaluating 46/105 - Question ID: 46\n",
      "Accuracy:0\n",
      "  Time: 10.23s\n",
      "\n",
      "Evaluating 47/105 - Question ID: 47\n",
      "Accuracy:100\n",
      "  Time: 8.29s\n",
      "\n",
      "Evaluating 48/105 - Question ID: 48\n",
      "  ✗ Failed: Unknown error after 1 attempts: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.\n",
      "\n",
      "Evaluating 49/105 - Question ID: 49\n",
      "Accuracy:100\n",
      "  Time: 7.86s\n",
      "\n",
      "Evaluating 50/105 - Question ID: 50\n",
      "Accuracy:100\n",
      "  Time: 10.48s\n",
      "\n",
      "Evaluating 51/105 - Question ID: 51\n",
      "Accuracy:100\n",
      "  Time: 11.12s\n",
      "\n",
      "Evaluating 52/105 - Question ID: 52\n",
      "Accuracy:0\n",
      "  Time: 14.15s\n",
      "\n",
      "Evaluating 53/105 - Question ID: 53\n",
      "Accuracy:100\n",
      "  Time: 13.70s\n",
      "\n",
      "Evaluating 54/105 - Question ID: 54\n",
      "Accuracy:0\n",
      "  Time: 14.36s\n",
      "\n",
      "Evaluating 55/105 - Question ID: 55\n",
      "Accuracy:100\n",
      "  Time: 17.68s\n",
      "\n",
      "Evaluating 56/105 - Question ID: 56\n",
      "Accuracy:100\n",
      "  Time: 8.52s\n",
      "\n",
      "Evaluating 57/105 - Question ID: 57\n",
      "Accuracy:100\n",
      "  Time: 12.27s\n",
      "\n",
      "Evaluating 58/105 - Question ID: 58\n",
      "Accuracy:100\n",
      "  Time: 13.10s\n",
      "\n",
      "Evaluating 59/105 - Question ID: 59\n",
      "Accuracy:0\n",
      "  Time: 10.03s\n",
      "\n",
      "Evaluating 60/105 - Question ID: 60\n",
      "Accuracy:100\n",
      "  Time: 9.35s\n",
      "\n",
      "Evaluating 61/105 - Question ID: 61\n",
      "Accuracy:100\n",
      "  Time: 9.66s\n",
      "\n",
      "Evaluating 62/105 - Question ID: 62\n",
      "Accuracy:100\n",
      "  Time: 13.32s\n",
      "\n",
      "Evaluating 63/105 - Question ID: 63\n",
      "Accuracy:100\n",
      "  Time: 14.42s\n",
      "\n",
      "Evaluating 64/105 - Question ID: 64\n",
      "Accuracy:100\n",
      "  Time: 8.81s\n",
      "\n",
      "Evaluating 65/105 - Question ID: 65\n",
      "Accuracy:100\n",
      "  Time: 7.67s\n",
      "\n",
      "Evaluating 66/105 - Question ID: 66\n",
      "Accuracy:100\n",
      "  Time: 12.57s\n",
      "\n",
      "Evaluating 67/105 - Question ID: 67\n",
      "Accuracy:100\n",
      "  Time: 6.37s\n",
      "\n",
      "Evaluating 68/105 - Question ID: 68\n",
      "Accuracy:100\n",
      "  Time: 6.36s\n",
      "\n",
      "Evaluating 69/105 - Question ID: 69\n",
      "Accuracy:0\n",
      "  Time: 11.45s\n",
      "\n",
      "Evaluating 70/105 - Question ID: 70\n",
      "Accuracy:100\n",
      "  Time: 12.08s\n",
      "\n",
      "Evaluating 71/105 - Question ID: 71\n",
      "Accuracy:100\n",
      "  Time: 8.12s\n",
      "\n",
      "Evaluating 72/105 - Question ID: 72\n",
      "Accuracy:100\n",
      "  Time: 13.38s\n",
      "\n",
      "Evaluating 73/105 - Question ID: 73\n",
      "Accuracy:100\n",
      "  Time: 10.34s\n",
      "\n",
      "Evaluating 74/105 - Question ID: 74\n",
      "Accuracy:100\n",
      "  Time: 7.56s\n",
      "\n",
      "Evaluating 75/105 - Question ID: 75\n",
      "Accuracy:0\n",
      "  Time: 14.13s\n",
      "\n",
      "Evaluating 76/105 - Question ID: 76\n",
      "Accuracy:100\n",
      "  Time: 15.36s\n",
      "\n",
      "Evaluating 77/105 - Question ID: 77\n",
      "Failed to parse Gemini JSON response: Expecting value: line 1 column 1 (char 0)\n",
      "Raw response: Here is the...\n",
      "  ✗ Failed: JSON parse error: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "Evaluating 78/105 - Question ID: 78\n",
      "Accuracy:100\n",
      "  Time: 11.15s\n",
      "\n",
      "Evaluating 79/105 - Question ID: 79\n",
      "Accuracy:100\n",
      "  Time: 8.33s\n",
      "\n",
      "Evaluating 80/105 - Question ID: 80\n",
      "Accuracy:100\n",
      "  Time: 12.07s\n",
      "\n",
      "Evaluating 81/105 - Question ID: 81\n",
      "Accuracy:0\n",
      "  Time: 11.58s\n",
      "\n",
      "Evaluating 82/105 - Question ID: 82\n",
      "Accuracy:100\n",
      "  Time: 17.08s\n",
      "\n",
      "Evaluating 83/105 - Question ID: 83\n",
      "Accuracy:100\n",
      "  Time: 6.71s\n",
      "\n",
      "Evaluating 84/105 - Question ID: 84\n",
      "Accuracy:100\n",
      "  Time: 10.89s\n",
      "\n",
      "Evaluating 85/105 - Question ID: 85\n",
      "Accuracy:100\n",
      "  Time: 6.27s\n",
      "\n",
      "Evaluating 86/105 - Question ID: 86\n",
      "Accuracy:100\n",
      "  Time: 6.74s\n",
      "\n",
      "Evaluating 87/105 - Question ID: 87\n",
      "Accuracy:100\n",
      "  Time: 9.54s\n",
      "\n",
      "Evaluating 88/105 - Question ID: 88\n",
      "Accuracy:100\n",
      "  Time: 10.02s\n",
      "\n",
      "Evaluating 89/105 - Question ID: 89\n",
      "Accuracy:100\n",
      "  Time: 11.36s\n",
      "\n",
      "Evaluating 90/105 - Question ID: 90\n",
      "  ✗ Failed: Unknown error after 1 attempts: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.\n",
      "\n",
      "Evaluating 91/105 - Question ID: 91\n",
      "Accuracy:100\n",
      "  Time: 6.22s\n",
      "\n",
      "Evaluating 92/105 - Question ID: 92\n",
      "Accuracy:100\n",
      "  Time: 11.78s\n",
      "\n",
      "Evaluating 93/105 - Question ID: 93\n",
      "Accuracy:100\n",
      "  Time: 13.20s\n",
      "\n",
      "Evaluating 94/105 - Question ID: 94\n",
      "Accuracy:100\n",
      "  Time: 9.62s\n",
      "\n",
      "Evaluating 95/105 - Question ID: 95\n",
      "Accuracy:100\n",
      "  Time: 10.14s\n",
      "\n",
      "Evaluating 96/105 - Question ID: 96\n",
      "Accuracy:100\n",
      "  Time: 11.79s\n",
      "\n",
      "Evaluating 97/105 - Question ID: 97\n",
      "Accuracy:100\n",
      "  Time: 14.56s\n",
      "\n",
      "Evaluating 98/105 - Question ID: 98\n",
      "Accuracy:100\n",
      "  Time: 9.43s\n",
      "\n",
      "Evaluating 99/105 - Question ID: 99\n",
      "Accuracy:0\n",
      "  Time: 8.96s\n",
      "\n",
      "Evaluating 100/105 - Question ID: 100\n",
      "Accuracy:100\n",
      "  Time: 8.72s\n",
      "\n",
      "Evaluating 101/105 - Question ID: 101\n",
      "Accuracy:100\n",
      "  Time: 9.92s\n",
      "\n",
      "Evaluating 102/105 - Question ID: 102\n",
      "Accuracy:0\n",
      "  Time: 10.75s\n",
      "\n",
      "Evaluating 103/105 - Question ID: 103\n",
      "Accuracy:100\n",
      "  Time: 10.95s\n",
      "\n",
      "Evaluating 104/105 - Question ID: 104\n",
      "Accuracy:100\n",
      "  Time: 13.21s\n",
      "\n",
      "Evaluating 105/105 - Question ID: 105\n",
      "Accuracy:100\n",
      "  Time: 16.18s\n",
      "\n",
      "============================================================\n",
      "EVALUATION COMPLETE: Gemini_embedding\n",
      "============================================================\n",
      "Backend: gemini\n",
      "Total evaluation time: 1193.23 seconds\n",
      "Successful evaluations: 102/105\n",
      "Success rate: 97.1%\n",
      "\n",
      "Average Scores:\n",
      "  Accuracy: 86.27\n",
      "\n",
      "Final rate limit usage: 6/150 requests, 1237/2000000 tokens\n",
      "\n",
      "Results saved to: rag_evaluation_results_gemini/gemini_embedding_evaluated_20250608_145115.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Vetex_RAG_evaluated = gemini_evaluator.evaluate_single_dataframe(\n",
    "    df=Vetex_RAG,\n",
    "    system_name=\"Gemini_embedding\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "246910cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "qids=[48,77,90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42ac0f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 3 questions...\n",
      "==================================================\n",
      "[Init] Initialized gemini-2.5-pro-preview-06-05 successfully with service account: gemini.json\n",
      "\n",
      "[1/3] Evaluating Question ID: 48\n",
      "  Score: 0/100\n",
      "  Rationale: The generated answer is fundamentally incorrect because it provides a list of tracked properties tha...\n",
      "\n",
      "[2/3] Evaluating Question ID: 77\n",
      "  Score: 100/100\n",
      "  Rationale: The generated answer provides a value for the Hubble constant ($73.24 \\pm 1.74 \\mathrm{~km} \\mathrm{...\n",
      "\n",
      "[3/3] Evaluating Question ID: 90\n",
      "[Backoff] Attempt 1/3 failed. Unknown error: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.\n",
      "[Backoff] Sleeping for 25.3 seconds (base: 30s, multiplier: 2.0)\n",
      "  Score: 100/100\n",
      "  Rationale: The generated answer correctly identifies one of the two primary strategies mentioned in the ideal a...\n"
     ]
    }
   ],
   "source": [
    "missing_question(qids, Vetex_RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f77aebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.70990476190475"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(86.27*102+200)/105"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fae36e",
   "metadata": {},
   "source": [
    "# Evaluate Gemini Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "633c4671",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_embedding_df=pd.read_pickle(\"results/gemini_embedding_results.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e4ef7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EVALUATING: Gemini_embedding (using gemini backend)\n",
      "============================================================\n",
      "All required columns found\n",
      "Available columns: ['question_id', 'question', 'ideal_solution', 'response', 'answer', 'sources', 'processing_time', 'success', 'error', 'embedding_system']\n",
      "Filtering by success column: 105 successful out of 105 total\n",
      "Rate limit status: 6/150 requests, 1237/2000000 tokens\n",
      "\n",
      "Evaluating 1/105 - Question ID: 1\n",
      "Accuracy:100\n",
      "  Time: 6.97s\n",
      "\n",
      "Evaluating 2/105 - Question ID: 2\n",
      "Accuracy:100\n",
      "  Time: 17.73s\n",
      "\n",
      "Evaluating 3/105 - Question ID: 3\n",
      "Accuracy:100\n",
      "  Time: 8.79s\n",
      "\n",
      "Evaluating 4/105 - Question ID: 4\n",
      "Accuracy:100\n",
      "  Time: 6.48s\n",
      "\n",
      "Evaluating 5/105 - Question ID: 5\n",
      "Accuracy:100\n",
      "  Time: 7.76s\n",
      "\n",
      "Evaluating 6/105 - Question ID: 6\n",
      "Accuracy:100\n",
      "  Time: 7.06s\n",
      "\n",
      "Evaluating 7/105 - Question ID: 7\n",
      "Accuracy:100\n",
      "  Time: 11.27s\n",
      "\n",
      "Evaluating 8/105 - Question ID: 8\n",
      "Accuracy:100\n",
      "  Time: 10.65s\n",
      "\n",
      "Evaluating 9/105 - Question ID: 9\n",
      "Accuracy:100\n",
      "  Time: 12.16s\n",
      "\n",
      "Evaluating 10/105 - Question ID: 10\n",
      "Accuracy:100\n",
      "  Time: 6.61s\n",
      "\n",
      "Evaluating 11/105 - Question ID: 11\n",
      "Accuracy:100\n",
      "  Time: 9.25s\n",
      "\n",
      "Evaluating 12/105 - Question ID: 12\n",
      "Accuracy:100\n",
      "  Time: 11.53s\n",
      "\n",
      "Evaluating 13/105 - Question ID: 13\n",
      "Accuracy:0\n",
      "  Time: 11.94s\n",
      "\n",
      "Evaluating 14/105 - Question ID: 14\n",
      "Accuracy:100\n",
      "  Time: 12.78s\n",
      "\n",
      "Evaluating 15/105 - Question ID: 15\n",
      "Accuracy:100\n",
      "  Time: 10.78s\n",
      "\n",
      "Evaluating 16/105 - Question ID: 16\n",
      "Accuracy:100\n",
      "  Time: 9.52s\n",
      "\n",
      "Evaluating 17/105 - Question ID: 17\n",
      "Accuracy:100\n",
      "  Time: 11.73s\n",
      "\n",
      "Evaluating 18/105 - Question ID: 18\n",
      "Accuracy:100\n",
      "  Time: 13.33s\n",
      "\n",
      "Evaluating 19/105 - Question ID: 19\n",
      "Accuracy:100\n",
      "  Time: 25.32s\n",
      "\n",
      "Evaluating 20/105 - Question ID: 20\n",
      "Accuracy:0\n",
      "  Time: 20.55s\n",
      "\n",
      "Evaluating 21/105 - Question ID: 21\n",
      "Accuracy:100\n",
      "  Time: 10.37s\n",
      "\n",
      "Evaluating 22/105 - Question ID: 22\n",
      "Accuracy:0\n",
      "  Time: 11.17s\n",
      "\n",
      "Evaluating 23/105 - Question ID: 23\n",
      "Accuracy:100\n",
      "  Time: 11.30s\n",
      "\n",
      "Evaluating 24/105 - Question ID: 24\n",
      "Accuracy:100\n",
      "  Time: 13.38s\n",
      "\n",
      "Evaluating 25/105 - Question ID: 25\n",
      "Accuracy:100\n",
      "  Time: 11.44s\n",
      "\n",
      "Evaluating 26/105 - Question ID: 26\n",
      "  ✗ Failed: Unknown error after 1 attempts: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.\n",
      "\n",
      "Evaluating 27/105 - Question ID: 27\n",
      "Accuracy:100\n",
      "  Time: 11.03s\n",
      "\n",
      "Evaluating 28/105 - Question ID: 28\n",
      "Accuracy:100\n",
      "  Time: 11.48s\n",
      "\n",
      "Evaluating 29/105 - Question ID: 29\n",
      "Accuracy:100\n",
      "  Time: 9.17s\n",
      "\n",
      "Evaluating 30/105 - Question ID: 30\n",
      "Accuracy:100\n",
      "  Time: 13.42s\n",
      "\n",
      "Evaluating 31/105 - Question ID: 31\n",
      "Accuracy:100\n",
      "  Time: 6.65s\n",
      "\n",
      "Evaluating 32/105 - Question ID: 32\n",
      "Accuracy:100\n",
      "  Time: 16.66s\n",
      "\n",
      "Evaluating 33/105 - Question ID: 33\n",
      "Accuracy:100\n",
      "  Time: 10.21s\n",
      "\n",
      "Evaluating 34/105 - Question ID: 34\n",
      "Accuracy:0\n",
      "  Time: 14.49s\n",
      "\n",
      "Evaluating 35/105 - Question ID: 35\n",
      "Accuracy:100\n",
      "  Time: 10.47s\n",
      "\n",
      "Evaluating 36/105 - Question ID: 36\n",
      "Accuracy:100\n",
      "  Time: 9.39s\n",
      "\n",
      "Evaluating 37/105 - Question ID: 37\n",
      "Accuracy:100\n",
      "  Time: 12.27s\n",
      "\n",
      "Evaluating 38/105 - Question ID: 38\n",
      "Accuracy:100\n",
      "  Time: 11.69s\n",
      "\n",
      "Evaluating 39/105 - Question ID: 39\n",
      "Accuracy:100\n",
      "  Time: 11.26s\n",
      "\n",
      "Evaluating 40/105 - Question ID: 40\n",
      "Accuracy:100\n",
      "  Time: 6.92s\n",
      "\n",
      "Evaluating 41/105 - Question ID: 41\n",
      "Accuracy:100\n",
      "  Time: 9.14s\n",
      "\n",
      "Evaluating 42/105 - Question ID: 42\n",
      "Accuracy:100\n",
      "  Time: 12.59s\n",
      "\n",
      "Evaluating 43/105 - Question ID: 43\n",
      "Accuracy:100\n",
      "  Time: 10.50s\n",
      "\n",
      "Evaluating 44/105 - Question ID: 44\n",
      "Accuracy:100\n",
      "  Time: 16.84s\n",
      "\n",
      "Evaluating 45/105 - Question ID: 45\n",
      "Failed to parse Gemini JSON response: Invalid \\escape: line 3 column 119 (char 145)\n",
      "Raw response: {\n",
      "  \"accuracy_score\": 100,\n",
      "  \"rationale\": \"The generated answer correctly lists all the fixed initial parameters mentioned in the ideal answer ($\\Omega_b = 0.049$, $h = 0.6711$, $n_s = 0.9624$, $\\sum m_{\\nu} = 0.0 eV$, $w = -1$). It also includes $\\Omega_{K}=0$, which is a correct additional paramet...\n",
      "  ✗ Failed: JSON parse error: Invalid \\escape: line 3 column 119 (char 145)\n",
      "\n",
      "Evaluating 46/105 - Question ID: 46\n",
      "Accuracy:0\n",
      "  Time: 7.67s\n",
      "\n",
      "Evaluating 47/105 - Question ID: 47\n",
      "Accuracy:100\n",
      "  Time: 5.49s\n",
      "\n",
      "Evaluating 48/105 - Question ID: 48\n",
      "Accuracy:0\n",
      "  Time: 17.35s\n",
      "\n",
      "Evaluating 49/105 - Question ID: 49\n",
      "Accuracy:100\n",
      "  Time: 9.41s\n",
      "\n",
      "Evaluating 50/105 - Question ID: 50\n",
      "Accuracy:100\n",
      "  Time: 14.68s\n",
      "\n",
      "Evaluating 51/105 - Question ID: 51\n",
      "Accuracy:100\n",
      "  Time: 7.74s\n",
      "\n",
      "Evaluating 52/105 - Question ID: 52\n",
      "Accuracy:0\n",
      "  Time: 13.21s\n",
      "\n",
      "Evaluating 53/105 - Question ID: 53\n",
      "Accuracy:100\n",
      "  Time: 11.87s\n",
      "\n",
      "Evaluating 54/105 - Question ID: 54\n",
      "Accuracy:0\n",
      "  Time: 8.71s\n",
      "\n",
      "Evaluating 55/105 - Question ID: 55\n",
      "Accuracy:0\n",
      "  Time: 21.71s\n",
      "\n",
      "Evaluating 56/105 - Question ID: 56\n",
      "Accuracy:100\n",
      "  Time: 11.16s\n",
      "\n",
      "Evaluating 57/105 - Question ID: 57\n",
      "Accuracy:100\n",
      "  Time: 17.31s\n",
      "\n",
      "Evaluating 58/105 - Question ID: 58\n",
      "Accuracy:100\n",
      "  Time: 14.98s\n",
      "\n",
      "Evaluating 59/105 - Question ID: 59\n",
      "Accuracy:100\n",
      "  Time: 10.85s\n",
      "\n",
      "Evaluating 60/105 - Question ID: 60\n",
      "Accuracy:100\n",
      "  Time: 8.05s\n",
      "\n",
      "Evaluating 61/105 - Question ID: 61\n",
      "Accuracy:100\n",
      "  Time: 7.84s\n",
      "\n",
      "Evaluating 62/105 - Question ID: 62\n",
      "Accuracy:100\n",
      "  Time: 11.01s\n",
      "\n",
      "Evaluating 63/105 - Question ID: 63\n",
      "Accuracy:100\n",
      "  Time: 9.23s\n",
      "\n",
      "Evaluating 64/105 - Question ID: 64\n",
      "Accuracy:100\n",
      "  Time: 8.88s\n",
      "\n",
      "Evaluating 65/105 - Question ID: 65\n",
      "Accuracy:100\n",
      "  Time: 6.87s\n",
      "\n",
      "Evaluating 66/105 - Question ID: 66\n",
      "Accuracy:100\n",
      "  Time: 14.94s\n",
      "\n",
      "Evaluating 67/105 - Question ID: 67\n",
      "Accuracy:100\n",
      "  Time: 12.51s\n",
      "\n",
      "Evaluating 68/105 - Question ID: 68\n",
      "Accuracy:100\n",
      "  Time: 9.44s\n",
      "\n",
      "Evaluating 69/105 - Question ID: 69\n",
      "Accuracy:0\n",
      "  Time: 8.96s\n",
      "\n",
      "Evaluating 70/105 - Question ID: 70\n",
      "Accuracy:0\n",
      "  Time: 5.98s\n",
      "\n",
      "Evaluating 71/105 - Question ID: 71\n",
      "Accuracy:100\n",
      "  Time: 7.95s\n",
      "\n",
      "Evaluating 72/105 - Question ID: 72\n",
      "Accuracy:100\n",
      "  Time: 11.98s\n",
      "\n",
      "Evaluating 73/105 - Question ID: 73\n",
      "Accuracy:100\n",
      "  Time: 12.03s\n",
      "\n",
      "Evaluating 74/105 - Question ID: 74\n",
      "Accuracy:100\n",
      "  Time: 9.75s\n",
      "\n",
      "Evaluating 75/105 - Question ID: 75\n",
      "Accuracy:0\n",
      "  Time: 17.54s\n",
      "\n",
      "Evaluating 76/105 - Question ID: 76\n",
      "Accuracy:100\n",
      "  Time: 18.22s\n",
      "\n",
      "Evaluating 77/105 - Question ID: 77\n",
      "Accuracy:100\n",
      "  Time: 19.87s\n",
      "\n",
      "Evaluating 78/105 - Question ID: 78\n",
      "Accuracy:100\n",
      "  Time: 10.44s\n",
      "\n",
      "Evaluating 79/105 - Question ID: 79\n",
      "Accuracy:100\n",
      "  Time: 9.14s\n",
      "\n",
      "Evaluating 80/105 - Question ID: 80\n",
      "Accuracy:100\n",
      "  Time: 10.37s\n",
      "\n",
      "Evaluating 81/105 - Question ID: 81\n",
      "Accuracy:0\n",
      "  Time: 11.88s\n",
      "\n",
      "Evaluating 82/105 - Question ID: 82\n",
      "Accuracy:100\n",
      "  Time: 11.88s\n",
      "\n",
      "Evaluating 83/105 - Question ID: 83\n",
      "Accuracy:100\n",
      "  Time: 7.37s\n",
      "\n",
      "Evaluating 84/105 - Question ID: 84\n",
      "Accuracy:100\n",
      "  Time: 13.33s\n",
      "\n",
      "Evaluating 85/105 - Question ID: 85\n",
      "Accuracy:100\n",
      "  Time: 8.39s\n",
      "\n",
      "Evaluating 86/105 - Question ID: 86\n",
      "Accuracy:100\n",
      "  Time: 6.78s\n",
      "\n",
      "Evaluating 87/105 - Question ID: 87\n",
      "Accuracy:100\n",
      "  Time: 11.22s\n",
      "\n",
      "Evaluating 88/105 - Question ID: 88\n",
      "Accuracy:100\n",
      "  Time: 14.44s\n",
      "\n",
      "Evaluating 89/105 - Question ID: 89\n",
      "Accuracy:100\n",
      "  Time: 10.55s\n",
      "\n",
      "Evaluating 90/105 - Question ID: 90\n",
      "Accuracy:100\n",
      "  Time: 11.16s\n",
      "\n",
      "Evaluating 91/105 - Question ID: 91\n",
      "Accuracy:100\n",
      "  Time: 7.17s\n",
      "\n",
      "Evaluating 92/105 - Question ID: 92\n",
      "Accuracy:100\n",
      "  Time: 9.96s\n",
      "\n",
      "Evaluating 93/105 - Question ID: 93\n",
      "Accuracy:100\n",
      "  Time: 13.28s\n",
      "\n",
      "Evaluating 94/105 - Question ID: 94\n",
      "Accuracy:100\n",
      "  Time: 10.55s\n",
      "\n",
      "Evaluating 95/105 - Question ID: 95\n",
      "Accuracy:100\n",
      "  Time: 11.55s\n",
      "\n",
      "Evaluating 96/105 - Question ID: 96\n",
      "Accuracy:100\n",
      "  Time: 7.70s\n",
      "\n",
      "Evaluating 97/105 - Question ID: 97\n",
      "Accuracy:100\n",
      "  Time: 18.22s\n",
      "\n",
      "Evaluating 98/105 - Question ID: 98\n",
      "Accuracy:100\n",
      "  Time: 10.24s\n",
      "\n",
      "Evaluating 99/105 - Question ID: 99\n",
      "Accuracy:100\n",
      "  Time: 6.24s\n",
      "\n",
      "Evaluating 100/105 - Question ID: 100\n",
      "Accuracy:100\n",
      "  Time: 7.68s\n",
      "\n",
      "Evaluating 101/105 - Question ID: 101\n",
      "Accuracy:100\n",
      "  Time: 8.38s\n",
      "\n",
      "Evaluating 102/105 - Question ID: 102\n",
      "Accuracy:0\n",
      "  Time: 13.48s\n",
      "\n",
      "Evaluating 103/105 - Question ID: 103\n",
      "Accuracy:100\n",
      "  Time: 15.49s\n",
      "\n",
      "Evaluating 104/105 - Question ID: 104\n",
      "Accuracy:100\n",
      "  Time: 11.59s\n",
      "\n",
      "Evaluating 105/105 - Question ID: 105\n",
      "Accuracy:100\n",
      "  Time: 13.60s\n",
      "\n",
      "============================================================\n",
      "EVALUATION COMPLETE: Gemini_embedding\n",
      "============================================================\n",
      "Backend: gemini\n",
      "Total evaluation time: 1204.95 seconds\n",
      "Successful evaluations: 103/105\n",
      "Success rate: 98.1%\n",
      "\n",
      "Average Scores:\n",
      "  Accuracy: 86.41\n",
      "\n",
      "Final rate limit usage: 6/150 requests, 1238/2000000 tokens\n",
      "\n",
      "Results saved to: rag_evaluation_results_gemini/gemini_embedding_evaluated_20250608_151120.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gemini_embedding_evaluated = gemini_evaluator.evaluate_single_dataframe(\n",
    "    df=gemini_embedding_df,\n",
    "    system_name=\"Gemini_embedding\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a0ef1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "qids=[26,45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7041b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 2 questions...\n",
      "==================================================\n",
      "[Init] Initialized gemini-2.5-pro-preview-06-05 successfully with service account: gemini.json\n",
      "\n",
      "[1/2] Evaluating Question ID: 26\n",
      "  Score: 0/100\n",
      "  Rationale: The generated answer correctly identifies the parameters that are varied (cosmological and astrophys...\n",
      "\n",
      "[2/2] Evaluating Question ID: 45\n",
      "Failed to parse Gemini JSON response: Invalid \\escape: line 3 column 243 (char 269)\n",
      "Raw response: {\n",
      "  \"accuracy_score\": 100,\n",
      "  \"rationale\": \"The generated answer correctly identifies all the fixed initial parameters and their corresponding values as listed in the ideal answer. It includes all the core factual content required. The additional information provided ($\\Omega_{K}=0$) is also correct ...\n",
      "  Failed: JSON parse error: Invalid \\escape: line 3 column 243 (char 269)\n"
     ]
    }
   ],
   "source": [
    "missing_question(qids, gemini_embedding_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c8dcdea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.71647619047619"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(86.41*103+100)/105"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5636f1",
   "metadata": {},
   "source": [
    "# gemini_no_rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "528f484f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_no_rag=pd.read_pickle(\"results/gemini_norag_results.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83210be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EVALUATING: Gemini_no_rag (using gemini backend)\n",
      "============================================================\n",
      "All required columns found\n",
      "Available columns: ['question_id', 'question', 'response', 'answer', 'sources', 'ideal_solution', 'processing_time', 'success', 'error', 'embedding_system']\n",
      "Filtering by success column: 105 successful out of 105 total\n",
      "Rate limit status: 6/150 requests, 1238/2000000 tokens\n",
      "\n",
      "Evaluating 1/105 - Question ID: 1\n",
      "Accuracy:0\n",
      "  Time: 9.16s\n",
      "\n",
      "Evaluating 2/105 - Question ID: 2\n",
      "Accuracy:0\n",
      "  Time: 9.92s\n",
      "\n",
      "Evaluating 3/105 - Question ID: 3\n",
      "Accuracy:0\n",
      "  Time: 6.27s\n",
      "\n",
      "Evaluating 4/105 - Question ID: 4\n",
      "Accuracy:0\n",
      "  Time: 8.07s\n",
      "\n",
      "Evaluating 5/105 - Question ID: 5\n",
      "Accuracy:0\n",
      "  Time: 12.16s\n",
      "\n",
      "Evaluating 6/105 - Question ID: 6\n",
      "Accuracy:0\n",
      "  Time: 16.82s\n",
      "\n",
      "Evaluating 7/105 - Question ID: 7\n",
      "Failed to parse Gemini JSON response: Unterminated string starting at: line 3 column 16 (char 40)\n",
      "Raw response: {\n",
      "  \"accuracy_score\": 0,\n",
      "  \"rationale\": \"The generated answer is fundamentally incorrect. It states that the best-fit value for 10^9 A_s is 3.044 with a 1-sigma constraint of 0.014. The ideal answer gives the value as (2.101^{+0.031}_{-0.034}) \\\\times 10...\n",
      "  ✗ Failed: JSON parse error: Unterminated string starting at: line 3 column 16 (char 40)\n",
      "\n",
      "Evaluating 8/105 - Question ID: 8\n",
      "Accuracy:0\n",
      "  Time: 17.61s\n",
      "\n",
      "Evaluating 9/105 - Question ID: 9\n",
      "Accuracy:0\n",
      "  Time: 10.87s\n",
      "\n",
      "Evaluating 10/105 - Question ID: 10\n",
      "Accuracy:0\n",
      "  Time: 13.63s\n",
      "\n",
      "Evaluating 11/105 - Question ID: 11\n",
      "Accuracy:0\n",
      "  Time: 10.51s\n",
      "\n",
      "Evaluating 12/105 - Question ID: 12\n",
      "  ✗ Failed: Unknown error after 1 attempts: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.\n",
      "\n",
      "Evaluating 13/105 - Question ID: 13\n",
      "Accuracy:100\n",
      "  Time: 14.43s\n",
      "\n",
      "Evaluating 14/105 - Question ID: 14\n",
      "Accuracy:0\n",
      "  Time: 21.92s\n",
      "\n",
      "Evaluating 15/105 - Question ID: 15\n",
      "Accuracy:100\n",
      "  Time: 10.07s\n",
      "\n",
      "Evaluating 16/105 - Question ID: 16\n",
      "Accuracy:100\n",
      "  Time: 15.66s\n",
      "\n",
      "Evaluating 17/105 - Question ID: 17\n",
      "Accuracy:0\n",
      "  Time: 13.72s\n",
      "\n",
      "Evaluating 18/105 - Question ID: 18\n",
      "Accuracy:0\n",
      "  Time: 23.80s\n",
      "\n",
      "Evaluating 19/105 - Question ID: 19\n",
      "Accuracy:100\n",
      "  Time: 21.16s\n",
      "\n",
      "Evaluating 20/105 - Question ID: 20\n",
      "Accuracy:100\n",
      "  Time: 12.11s\n",
      "\n",
      "Evaluating 21/105 - Question ID: 21\n",
      "Accuracy:0\n",
      "  Time: 11.18s\n",
      "\n",
      "Evaluating 22/105 - Question ID: 22\n",
      "Accuracy:100\n",
      "  Time: 15.46s\n",
      "\n",
      "Evaluating 23/105 - Question ID: 23\n",
      "Accuracy:0\n",
      "  Time: 12.16s\n",
      "\n",
      "Evaluating 24/105 - Question ID: 24\n",
      "Accuracy:0\n",
      "  Time: 7.48s\n",
      "\n",
      "Evaluating 25/105 - Question ID: 25\n",
      "Accuracy:100\n",
      "  Time: 21.36s\n",
      "\n",
      "Evaluating 26/105 - Question ID: 26\n",
      "Accuracy:0\n",
      "  Time: 10.03s\n",
      "\n",
      "Evaluating 27/105 - Question ID: 27\n",
      "Accuracy:0\n",
      "  Time: 17.54s\n",
      "\n",
      "Evaluating 28/105 - Question ID: 28\n",
      "Accuracy:0\n",
      "  Time: 12.06s\n",
      "\n",
      "Evaluating 29/105 - Question ID: 29\n",
      "Accuracy:0\n",
      "  Time: 12.08s\n",
      "\n",
      "Evaluating 30/105 - Question ID: 30\n",
      "Accuracy:100\n",
      "  Time: 16.98s\n",
      "\n",
      "Evaluating 31/105 - Question ID: 31\n",
      "Accuracy:100\n",
      "  Time: 22.04s\n",
      "\n",
      "Evaluating 32/105 - Question ID: 32\n",
      "Accuracy:0\n",
      "  Time: 17.27s\n",
      "\n",
      "Evaluating 33/105 - Question ID: 33\n",
      "Accuracy:0\n",
      "  Time: 13.04s\n",
      "\n",
      "Evaluating 34/105 - Question ID: 34\n",
      "Accuracy:0\n",
      "  Time: 16.84s\n",
      "\n",
      "Evaluating 35/105 - Question ID: 35\n",
      "Accuracy:0\n",
      "  Time: 9.67s\n",
      "\n",
      "Evaluating 36/105 - Question ID: 36\n",
      "Accuracy:100\n",
      "  Time: 14.48s\n",
      "\n",
      "Evaluating 37/105 - Question ID: 37\n",
      "Accuracy:0\n",
      "  Time: 8.85s\n",
      "\n",
      "Evaluating 38/105 - Question ID: 38\n",
      "Accuracy:0\n",
      "  Time: 13.11s\n",
      "\n",
      "Evaluating 39/105 - Question ID: 39\n",
      "Accuracy:0\n",
      "  Time: 8.20s\n",
      "\n",
      "Evaluating 40/105 - Question ID: 40\n",
      "Accuracy:100\n",
      "  Time: 10.54s\n",
      "\n",
      "Evaluating 41/105 - Question ID: 41\n",
      "Accuracy:0\n",
      "  Time: 13.43s\n",
      "\n",
      "Evaluating 42/105 - Question ID: 42\n",
      "Accuracy:100\n",
      "  Time: 11.14s\n",
      "\n",
      "Evaluating 43/105 - Question ID: 43\n",
      "Accuracy:100\n",
      "  Time: 12.27s\n",
      "\n",
      "Evaluating 44/105 - Question ID: 44\n",
      "Accuracy:0\n",
      "  Time: 16.46s\n",
      "\n",
      "Evaluating 45/105 - Question ID: 45\n",
      "Accuracy:0\n",
      "  Time: 14.99s\n",
      "\n",
      "Evaluating 46/105 - Question ID: 46\n",
      "Accuracy:0\n",
      "  Time: 6.56s\n",
      "\n",
      "Evaluating 47/105 - Question ID: 47\n",
      "Accuracy:0\n",
      "  Time: 12.27s\n",
      "\n",
      "Evaluating 48/105 - Question ID: 48\n",
      "Accuracy:100\n",
      "  Time: 9.71s\n",
      "\n",
      "Evaluating 49/105 - Question ID: 49\n",
      "Accuracy:0\n",
      "  Time: 12.82s\n",
      "\n",
      "Evaluating 50/105 - Question ID: 50\n",
      "Accuracy:0\n",
      "  Time: 14.45s\n",
      "\n",
      "Evaluating 51/105 - Question ID: 51\n",
      "Accuracy:0\n",
      "  Time: 6.33s\n",
      "\n",
      "Evaluating 52/105 - Question ID: 52\n",
      "Accuracy:100\n",
      "  Time: 12.68s\n",
      "\n",
      "Evaluating 53/105 - Question ID: 53\n",
      "Accuracy:0\n",
      "  Time: 13.23s\n",
      "\n",
      "Evaluating 54/105 - Question ID: 54\n",
      "Accuracy:0\n",
      "  Time: 27.54s\n",
      "\n",
      "Evaluating 55/105 - Question ID: 55\n",
      "Accuracy:0\n",
      "  Time: 11.05s\n",
      "\n",
      "Evaluating 56/105 - Question ID: 56\n",
      "Accuracy:0\n",
      "  Time: 17.75s\n",
      "\n",
      "Evaluating 57/105 - Question ID: 57\n",
      "Accuracy:100\n",
      "  Time: 10.82s\n",
      "\n",
      "Evaluating 58/105 - Question ID: 58\n",
      "Accuracy:0\n",
      "  Time: 11.88s\n",
      "\n",
      "Evaluating 59/105 - Question ID: 59\n",
      "Accuracy:0\n",
      "  Time: 14.34s\n",
      "\n",
      "Evaluating 60/105 - Question ID: 60\n",
      "Accuracy:0\n",
      "  Time: 20.23s\n",
      "\n",
      "Evaluating 61/105 - Question ID: 61\n",
      "Accuracy:0\n",
      "  Time: 9.58s\n",
      "\n",
      "Evaluating 62/105 - Question ID: 62\n",
      "Accuracy:0\n",
      "  Time: 11.76s\n",
      "\n",
      "Evaluating 63/105 - Question ID: 63\n",
      "Accuracy:0\n",
      "  Time: 15.06s\n",
      "\n",
      "Evaluating 64/105 - Question ID: 64\n",
      "Accuracy:100\n",
      "  Time: 9.11s\n",
      "\n",
      "Evaluating 65/105 - Question ID: 65\n",
      "Accuracy:0\n",
      "  Time: 17.09s\n",
      "\n",
      "Evaluating 66/105 - Question ID: 66\n",
      "Accuracy:0\n",
      "  Time: 15.66s\n",
      "\n",
      "Evaluating 67/105 - Question ID: 67\n",
      "Accuracy:0\n",
      "  Time: 8.21s\n",
      "\n",
      "Evaluating 68/105 - Question ID: 68\n",
      "Failed to parse Gemini JSON response: Unterminated string starting at: line 3 column 16 (char 40)\n",
      "Raw response: {\n",
      "  \"accuracy_score\": 0,\n",
      "  \"rationale\": \"The user's question asks for the *leading* source of scatter in the Period-Luminosity relations for HST observations of SN hosts. The ideal answer identifies this as 'Uncertainty in the Cephid background,' which refers to photometric crowding. The generated a...\n",
      "  ✗ Failed: JSON parse error: Unterminated string starting at: line 3 column 16 (char 40)\n",
      "\n",
      "Evaluating 69/105 - Question ID: 69\n",
      "Accuracy:0\n",
      "  Time: 9.51s\n",
      "\n",
      "Evaluating 70/105 - Question ID: 70\n",
      "Accuracy:0\n",
      "  Time: 21.53s\n",
      "\n",
      "Evaluating 71/105 - Question ID: 71\n",
      "Accuracy:0\n",
      "  Time: 18.17s\n",
      "\n",
      "Evaluating 72/105 - Question ID: 72\n",
      "Accuracy:0\n",
      "  Time: 10.05s\n",
      "\n",
      "Evaluating 73/105 - Question ID: 73\n",
      "Accuracy:0\n",
      "  Time: 10.44s\n",
      "\n",
      "Evaluating 74/105 - Question ID: 74\n",
      "Accuracy:0\n",
      "  Time: 14.28s\n",
      "\n",
      "Evaluating 75/105 - Question ID: 75\n",
      "Accuracy:0\n",
      "  Time: 17.22s\n",
      "\n",
      "Evaluating 76/105 - Question ID: 76\n",
      "Accuracy:0\n",
      "  Time: 17.39s\n",
      "\n",
      "Evaluating 77/105 - Question ID: 77\n",
      "Accuracy:100\n",
      "  Time: 22.88s\n",
      "\n",
      "Evaluating 78/105 - Question ID: 78\n",
      "Accuracy:0\n",
      "  Time: 15.78s\n",
      "\n",
      "Evaluating 79/105 - Question ID: 79\n",
      "Accuracy:0\n",
      "  Time: 11.16s\n",
      "\n",
      "Evaluating 80/105 - Question ID: 80\n",
      "Accuracy:0\n",
      "  Time: 16.08s\n",
      "\n",
      "Evaluating 81/105 - Question ID: 81\n",
      "  ✗ Failed: Unknown error after 1 attempts: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.\n",
      "\n",
      "Evaluating 82/105 - Question ID: 82\n",
      "Accuracy:0\n",
      "  Time: 19.63s\n",
      "\n",
      "Evaluating 83/105 - Question ID: 83\n",
      "Accuracy:100\n",
      "  Time: 12.48s\n",
      "\n",
      "Evaluating 84/105 - Question ID: 84\n",
      "Accuracy:0\n",
      "  Time: 21.92s\n",
      "\n",
      "Evaluating 85/105 - Question ID: 85\n",
      "Accuracy:100\n",
      "  Time: 8.34s\n",
      "\n",
      "Evaluating 86/105 - Question ID: 86\n",
      "Accuracy:0\n",
      "  Time: 15.43s\n",
      "\n",
      "Evaluating 87/105 - Question ID: 87\n",
      "Accuracy:0\n",
      "  Time: 8.35s\n",
      "\n",
      "Evaluating 88/105 - Question ID: 88\n",
      "Accuracy:100\n",
      "  Time: 11.81s\n",
      "\n",
      "Evaluating 89/105 - Question ID: 89\n",
      "Accuracy:0\n",
      "  Time: 7.76s\n",
      "\n",
      "Evaluating 90/105 - Question ID: 90\n",
      "Accuracy:100\n",
      "  Time: 14.97s\n",
      "\n",
      "Evaluating 91/105 - Question ID: 91\n",
      "Accuracy:100\n",
      "  Time: 8.05s\n",
      "\n",
      "Evaluating 92/105 - Question ID: 92\n",
      "Accuracy:100\n",
      "  Time: 11.15s\n",
      "\n",
      "Evaluating 93/105 - Question ID: 93\n",
      "  ✗ Failed: Unknown error after 1 attempts: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.\n",
      "\n",
      "Evaluating 94/105 - Question ID: 94\n",
      "Accuracy:0\n",
      "  Time: 18.89s\n",
      "\n",
      "Evaluating 95/105 - Question ID: 95\n",
      "Accuracy:0\n",
      "  Time: 11.15s\n",
      "\n",
      "Evaluating 96/105 - Question ID: 96\n",
      "Accuracy:0\n",
      "  Time: 8.08s\n",
      "\n",
      "Evaluating 97/105 - Question ID: 97\n",
      "Accuracy:100\n",
      "  Time: 12.73s\n",
      "\n",
      "Evaluating 98/105 - Question ID: 98\n",
      "Accuracy:0\n",
      "  Time: 14.23s\n",
      "\n",
      "Evaluating 99/105 - Question ID: 99\n",
      "Accuracy:0\n",
      "  Time: 16.42s\n",
      "\n",
      "Evaluating 100/105 - Question ID: 100\n",
      "Accuracy:0\n",
      "  Time: 10.12s\n",
      "\n",
      "Evaluating 101/105 - Question ID: 101\n",
      "Accuracy:100\n",
      "  Time: 15.72s\n",
      "\n",
      "Evaluating 102/105 - Question ID: 102\n",
      "Accuracy:0\n",
      "  Time: 21.32s\n",
      "\n",
      "Evaluating 103/105 - Question ID: 103\n",
      "Accuracy:0\n",
      "  Time: 19.25s\n",
      "\n",
      "Evaluating 104/105 - Question ID: 104\n",
      "Accuracy:100\n",
      "  Time: 8.90s\n",
      "\n",
      "Evaluating 105/105 - Question ID: 105\n",
      "Accuracy:0\n",
      "  Time: 11.49s\n",
      "\n",
      "============================================================\n",
      "EVALUATION COMPLETE: Gemini_no_rag\n",
      "============================================================\n",
      "Backend: gemini\n",
      "Total evaluation time: 1487.87 seconds\n",
      "Successful evaluations: 100/105\n",
      "Success rate: 95.2%\n",
      "\n",
      "Average Scores:\n",
      "  Accuracy: 27.00\n",
      "\n",
      "Final rate limit usage: 1/150 requests, 177/2000000 tokens\n",
      "\n",
      "Results saved to: rag_evaluation_results_gemini/gemini_no_rag_evaluated_20250608_153608.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gemini_no_rag_eval = gemini_evaluator.evaluate_single_dataframe(\n",
    "    df=gemini_no_rag,\n",
    "    system_name=\"Gemini_no_rag\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f08654f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "qids=[7,12,68,81,93]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93604236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 5 questions...\n",
      "==================================================\n",
      "[Init] Initialized gemini-2.5-pro-preview-06-05 successfully with service account: gemini.json\n",
      "\n",
      "[1/5] Evaluating Question ID: 7\n",
      "  Score: 0/100\n",
      "  Rationale: The generated answer provides a best-fit value for 10^9 A_s as 3.044 and a 1-sigma constraint of 0.0...\n",
      "\n",
      "[2/5] Evaluating Question ID: 12\n",
      "  Score: 0/100\n",
      "  Rationale: The generated answer is factually correct in its own right; BAO is indeed used as a standard ruler t...\n",
      "\n",
      "[3/5] Evaluating Question ID: 68\n",
      "Failed to parse Gemini JSON response: Unterminated string starting at: line 3 column 16 (char 40)\n",
      "Raw response: {\n",
      "  \"accuracy_score\": 0,\n",
      "  \"rationale\": \"The user's question asks for the *leading* source of scatter in the Period-Luminosity relations for HST observations of SN hosts. The ideal answer identifies this as 'Uncertainty in the Cephid background,' which refers to photometric crowding. The generated a...\n",
      "  Failed: JSON parse error: Unterminated string starting at: line 3 column 16 (char 40)\n",
      "\n",
      "[4/5] Evaluating Question ID: 81\n",
      "  Score: 100/100\n",
      "  Rationale: The generated answer correctly identifies the central value of the Hubble Constant (73.24 km s^-1 Mp...\n",
      "\n",
      "[5/5] Evaluating Question ID: 93\n",
      "  Score: 100/100\n",
      "  Rationale: The generated answer states that the running of the spectral index is 'consistent with zero'. The id...\n"
     ]
    }
   ],
   "source": [
    "missing_question(qids, gemini_no_rag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc9a2bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.61904761904762"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(27*100+200)/105"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32f2234",
   "metadata": {},
   "source": [
    "# Evaluate Vanilla PaperQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b131611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: GOOGLE_API_KEY found in environment. Removing to use service account.\n",
      "[Init] Initialized gemini-2.5-pro-preview-06-05 successfully with service account: gemini.json\n",
      "Initialized evaluation system with gemini backend\n",
      "Using model: gemini-2.5-pro-preview-06-05\n"
     ]
    }
   ],
   "source": [
    "gemini_evaluator = SingleRAGEvaluationSystem(evaluator_backend=\"gemini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3072195e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized evaluation system with autogen backend\n",
      "Using model: o3-mini\n"
     ]
    }
   ],
   "source": [
    "evaluator=SingleRAGEvaluationSystem(evaluator_backend=\"autogen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc2654c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb4f4c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "paperqa=pd.read_pickle(\"results/paperqa2_valina_gpt4.1_results_final.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba6d551e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EVALUATING: paperqa_valina_gpt4.1 (using gemini backend)\n",
      "============================================================\n",
      "All required columns found\n",
      "Available columns: ['question_id', 'question', 'response', 'answer', 'sources', 'ideal_solution', 'processing_time', 'success', 'error', 'embedding_system']\n",
      "Filtering by success column: 105 successful out of 105 total\n",
      "Rate limit status: 0/150 requests, 0/2000000 tokens\n",
      "\n",
      "Evaluating 1/105 - Question ID: 1\n",
      "Accuracy:100\n",
      "  Time: 7.77s\n",
      "\n",
      "Evaluating 2/105 - Question ID: 2\n",
      "Accuracy:100\n",
      "  Time: 14.64s\n",
      "\n",
      "Evaluating 3/105 - Question ID: 3\n",
      "Accuracy:100\n",
      "  Time: 7.78s\n",
      "\n",
      "Evaluating 4/105 - Question ID: 4\n",
      "Accuracy:100\n",
      "  Time: 98.79s\n",
      "\n",
      "Evaluating 5/105 - Question ID: 5\n",
      "Accuracy:100\n",
      "  Time: 9.51s\n",
      "\n",
      "Evaluating 6/105 - Question ID: 6\n",
      "Accuracy:100\n",
      "  Time: 9.94s\n",
      "\n",
      "Evaluating 7/105 - Question ID: 7\n",
      "Accuracy:100\n",
      "  Time: 10.75s\n",
      "\n",
      "Evaluating 8/105 - Question ID: 8\n",
      "Accuracy:0\n",
      "  Time: 20.40s\n",
      "\n",
      "Evaluating 9/105 - Question ID: 9\n",
      "Accuracy:0\n",
      "  Time: 8.66s\n",
      "\n",
      "Evaluating 10/105 - Question ID: 10\n",
      "Accuracy:100\n",
      "  Time: 16.67s\n",
      "\n",
      "Evaluating 11/105 - Question ID: 11\n",
      "Accuracy:100\n",
      "  Time: 12.41s\n",
      "\n",
      "Evaluating 12/105 - Question ID: 12\n",
      "Accuracy:100\n",
      "  Time: 9.09s\n",
      "\n",
      "Evaluating 13/105 - Question ID: 13\n",
      "Accuracy:100\n",
      "  Time: 9.85s\n",
      "\n",
      "Evaluating 14/105 - Question ID: 14\n",
      "Accuracy:100\n",
      "  Time: 16.76s\n",
      "\n",
      "Evaluating 15/105 - Question ID: 15\n",
      "Accuracy:100\n",
      "  Time: 17.30s\n",
      "\n",
      "Evaluating 16/105 - Question ID: 16\n",
      "Accuracy:100\n",
      "  Time: 10.93s\n",
      "\n",
      "Evaluating 17/105 - Question ID: 17\n",
      "Accuracy:100\n",
      "  Time: 10.53s\n",
      "\n",
      "Evaluating 18/105 - Question ID: 18\n",
      "Accuracy:100\n",
      "  Time: 10.85s\n",
      "\n",
      "Evaluating 19/105 - Question ID: 19\n",
      "Accuracy:100\n",
      "  Time: 11.56s\n",
      "\n",
      "Evaluating 20/105 - Question ID: 20\n",
      "Accuracy:100\n",
      "  Time: 19.26s\n",
      "\n",
      "Evaluating 21/105 - Question ID: 21\n",
      "Accuracy:100\n",
      "  Time: 11.39s\n",
      "\n",
      "Evaluating 22/105 - Question ID: 22\n",
      "Accuracy:100\n",
      "  Time: 10.28s\n",
      "\n",
      "Evaluating 23/105 - Question ID: 23\n",
      "Accuracy:100\n",
      "  Time: 10.95s\n",
      "\n",
      "Evaluating 24/105 - Question ID: 24\n",
      "Accuracy:100\n",
      "  Time: 13.02s\n",
      "\n",
      "Evaluating 25/105 - Question ID: 25\n",
      "Accuracy:0\n",
      "  Time: 14.17s\n",
      "\n",
      "Evaluating 26/105 - Question ID: 26\n",
      "Accuracy:100\n",
      "  Time: 19.65s\n",
      "\n",
      "Evaluating 27/105 - Question ID: 27\n",
      "Accuracy:100\n",
      "  Time: 10.34s\n",
      "\n",
      "Evaluating 28/105 - Question ID: 28\n",
      "Accuracy:100\n",
      "  Time: 11.14s\n",
      "\n",
      "Evaluating 29/105 - Question ID: 29\n",
      "Accuracy:100\n",
      "  Time: 8.87s\n",
      "\n",
      "Evaluating 30/105 - Question ID: 30\n",
      "Accuracy:100\n",
      "  Time: 14.58s\n",
      "\n",
      "Evaluating 31/105 - Question ID: 31\n",
      "Accuracy:100\n",
      "  Time: 11.63s\n",
      "\n",
      "Evaluating 32/105 - Question ID: 32\n",
      "Accuracy:100\n",
      "  Time: 13.04s\n",
      "\n",
      "Evaluating 33/105 - Question ID: 33\n",
      "Accuracy:100\n",
      "  Time: 11.38s\n",
      "\n",
      "Evaluating 34/105 - Question ID: 34\n",
      "Accuracy:0\n",
      "  Time: 17.68s\n",
      "\n",
      "Evaluating 35/105 - Question ID: 35\n",
      "Accuracy:100\n",
      "  Time: 12.12s\n",
      "\n",
      "Evaluating 36/105 - Question ID: 36\n",
      "Accuracy:100\n",
      "  Time: 9.65s\n",
      "\n",
      "Evaluating 37/105 - Question ID: 37\n",
      "Accuracy:100\n",
      "  Time: 8.43s\n",
      "\n",
      "Evaluating 38/105 - Question ID: 38\n",
      "Accuracy:100\n",
      "  Time: 7.11s\n",
      "\n",
      "Evaluating 39/105 - Question ID: 39\n",
      "Accuracy:100\n",
      "  Time: 11.04s\n",
      "\n",
      "Evaluating 40/105 - Question ID: 40\n",
      "Accuracy:100\n",
      "  Time: 11.04s\n",
      "\n",
      "Evaluating 41/105 - Question ID: 41\n",
      "Accuracy:100\n",
      "  Time: 8.83s\n",
      "\n",
      "Evaluating 42/105 - Question ID: 42\n",
      "Accuracy:100\n",
      "  Time: 9.62s\n",
      "\n",
      "Evaluating 43/105 - Question ID: 43\n",
      "Accuracy:100\n",
      "  Time: 10.07s\n",
      "\n",
      "Evaluating 44/105 - Question ID: 44\n",
      "Accuracy:0\n",
      "  Time: 16.66s\n",
      "\n",
      "Evaluating 45/105 - Question ID: 45\n",
      "Accuracy:100\n",
      "  Time: 13.31s\n",
      "\n",
      "Evaluating 46/105 - Question ID: 46\n",
      "Accuracy:0\n",
      "  Time: 7.72s\n",
      "\n",
      "Evaluating 47/105 - Question ID: 47\n",
      "Accuracy:0\n",
      "  Time: 13.17s\n",
      "\n",
      "Evaluating 48/105 - Question ID: 48\n",
      "Accuracy:0\n",
      "  Time: 18.77s\n",
      "\n",
      "Evaluating 49/105 - Question ID: 49\n",
      "Accuracy:100\n",
      "  Time: 8.13s\n",
      "\n",
      "Evaluating 50/105 - Question ID: 50\n",
      "Accuracy:100\n",
      "  Time: 11.24s\n",
      "\n",
      "Evaluating 51/105 - Question ID: 51\n",
      "Accuracy:100\n",
      "  Time: 10.18s\n",
      "\n",
      "Evaluating 52/105 - Question ID: 52\n",
      "Accuracy:100\n",
      "  Time: 12.10s\n",
      "\n",
      "Evaluating 53/105 - Question ID: 53\n",
      "Accuracy:100\n",
      "  Time: 20.62s\n",
      "\n",
      "Evaluating 54/105 - Question ID: 54\n",
      "Accuracy:0\n",
      "  Time: 8.85s\n",
      "\n",
      "Evaluating 55/105 - Question ID: 55\n",
      "Accuracy:100\n",
      "  Time: 9.93s\n",
      "\n",
      "Evaluating 56/105 - Question ID: 56\n",
      "Accuracy:100\n",
      "  Time: 15.01s\n",
      "\n",
      "Evaluating 57/105 - Question ID: 57\n",
      "Accuracy:100\n",
      "  Time: 10.19s\n",
      "\n",
      "Evaluating 58/105 - Question ID: 58\n",
      "Accuracy:100\n",
      "  Time: 13.45s\n",
      "\n",
      "Evaluating 59/105 - Question ID: 59\n",
      "Accuracy:100\n",
      "  Time: 7.92s\n",
      "\n",
      "Evaluating 60/105 - Question ID: 60\n",
      "Accuracy:100\n",
      "  Time: 10.44s\n",
      "\n",
      "Evaluating 61/105 - Question ID: 61\n",
      "Accuracy:0\n",
      "  Time: 12.06s\n",
      "\n",
      "Evaluating 62/105 - Question ID: 62\n",
      "Accuracy:0\n",
      "  Time: 11.20s\n",
      "\n",
      "Evaluating 63/105 - Question ID: 63\n",
      "Accuracy:100\n",
      "  Time: 13.79s\n",
      "\n",
      "Evaluating 64/105 - Question ID: 64\n",
      "Accuracy:100\n",
      "  Time: 8.08s\n",
      "\n",
      "Evaluating 65/105 - Question ID: 65\n",
      "Accuracy:100\n",
      "  Time: 11.78s\n",
      "\n",
      "Evaluating 66/105 - Question ID: 66\n",
      "Accuracy:100\n",
      "  Time: 26.51s\n",
      "\n",
      "Evaluating 67/105 - Question ID: 67\n",
      "Accuracy:100\n",
      "  Time: 11.33s\n",
      "\n",
      "Evaluating 68/105 - Question ID: 68\n",
      "Accuracy:100\n",
      "  Time: 10.99s\n",
      "\n",
      "Evaluating 69/105 - Question ID: 69\n",
      "Accuracy:100\n",
      "  Time: 11.40s\n",
      "\n",
      "Evaluating 70/105 - Question ID: 70\n",
      "Accuracy:100\n",
      "  Time: 14.22s\n",
      "\n",
      "Evaluating 71/105 - Question ID: 71\n",
      "Accuracy:100\n",
      "  Time: 8.88s\n",
      "\n",
      "Evaluating 72/105 - Question ID: 72\n",
      "Accuracy:100\n",
      "  Time: 13.55s\n",
      "\n",
      "Evaluating 73/105 - Question ID: 73\n",
      "Accuracy:100\n",
      "  Time: 9.17s\n",
      "\n",
      "Evaluating 74/105 - Question ID: 74\n",
      "Accuracy:0\n",
      "  Time: 15.75s\n",
      "\n",
      "Evaluating 75/105 - Question ID: 75\n",
      "Accuracy:0\n",
      "  Time: 20.45s\n",
      "\n",
      "Evaluating 76/105 - Question ID: 76\n",
      "Accuracy:100\n",
      "  Time: 16.73s\n",
      "\n",
      "Evaluating 77/105 - Question ID: 77\n",
      "[Backoff] Attempt 1/3 failed. Unknown error: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.\n",
      "[Backoff] Sleeping for 65.4 seconds (base: 60s, multiplier: 2.0)\n",
      "[Backoff] Attempt 2/3 failed. Unknown error: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.\n",
      "[Backoff] Sleeping for 108.6 seconds (base: 60s, multiplier: 2.0)\n",
      "Accuracy:0\n",
      "  Time: 238.02s\n",
      "\n",
      "Evaluating 78/105 - Question ID: 78\n",
      "Accuracy:100\n",
      "  Time: 12.52s\n",
      "\n",
      "Evaluating 79/105 - Question ID: 79\n",
      "Accuracy:100\n",
      "  Time: 7.35s\n",
      "\n",
      "Evaluating 80/105 - Question ID: 80\n",
      "Accuracy:0\n",
      "  Time: 15.35s\n",
      "\n",
      "Evaluating 81/105 - Question ID: 81\n",
      "Accuracy:100\n",
      "  Time: 11.27s\n",
      "\n",
      "Evaluating 82/105 - Question ID: 82\n",
      "Accuracy:100\n",
      "  Time: 14.39s\n",
      "\n",
      "Evaluating 83/105 - Question ID: 83\n",
      "Accuracy:100\n",
      "  Time: 6.68s\n",
      "\n",
      "Evaluating 84/105 - Question ID: 84\n",
      "Accuracy:100\n",
      "  Time: 13.81s\n",
      "\n",
      "Evaluating 85/105 - Question ID: 85\n",
      "Accuracy:100\n",
      "  Time: 7.72s\n",
      "\n",
      "Evaluating 86/105 - Question ID: 86\n",
      "Accuracy:100\n",
      "  Time: 9.37s\n",
      "\n",
      "Evaluating 87/105 - Question ID: 87\n",
      "Accuracy:100\n",
      "  Time: 9.33s\n",
      "\n",
      "Evaluating 88/105 - Question ID: 88\n",
      "Accuracy:100\n",
      "  Time: 19.56s\n",
      "\n",
      "Evaluating 89/105 - Question ID: 89\n",
      "Accuracy:100\n",
      "  Time: 13.43s\n",
      "\n",
      "Evaluating 90/105 - Question ID: 90\n",
      "Accuracy:100\n",
      "  Time: 9.32s\n",
      "\n",
      "Evaluating 91/105 - Question ID: 91\n",
      "Accuracy:100\n",
      "  Time: 11.76s\n",
      "\n",
      "Evaluating 92/105 - Question ID: 92\n",
      "Accuracy:100\n",
      "  Time: 10.89s\n",
      "\n",
      "Evaluating 93/105 - Question ID: 93\n",
      "Accuracy:100\n",
      "  Time: 11.10s\n",
      "\n",
      "Evaluating 94/105 - Question ID: 94\n",
      "Accuracy:0\n",
      "  Time: 8.98s\n",
      "\n",
      "Evaluating 95/105 - Question ID: 95\n",
      "Accuracy:100\n",
      "  Time: 9.12s\n",
      "\n",
      "Evaluating 96/105 - Question ID: 96\n",
      "Accuracy:100\n",
      "  Time: 7.94s\n",
      "\n",
      "Evaluating 97/105 - Question ID: 97\n",
      "Accuracy:100\n",
      "  Time: 11.39s\n",
      "\n",
      "Evaluating 98/105 - Question ID: 98\n",
      "Accuracy:100\n",
      "  Time: 19.35s\n",
      "\n",
      "Evaluating 99/105 - Question ID: 99\n",
      "Accuracy:100\n",
      "  Time: 9.69s\n",
      "\n",
      "Evaluating 100/105 - Question ID: 100\n",
      "Accuracy:0\n",
      "  Time: 13.13s\n",
      "\n",
      "Evaluating 101/105 - Question ID: 101\n",
      "Accuracy:100\n",
      "  Time: 13.61s\n",
      "\n",
      "Evaluating 102/105 - Question ID: 102\n",
      "Failed to parse Gemini JSON response: Unterminated string starting at: line 3 column 16 (char 40)\n",
      "Raw response: {\n",
      "  \"accuracy_score\": 0,\n",
      "  \"rationale\": \"The generated answer provides a completely different physical explanation than the ideal answer. The ideal answer states that the weaker constraint is due to a parameter degeneracy involving the interaction rate Γ_{0, nadm} as N_{idr} approaches zero. The gen...\n",
      "  ✗ Failed: JSON parse error: Unterminated string starting at: line 3 column 16 (char 40)\n",
      "\n",
      "Evaluating 103/105 - Question ID: 103\n",
      "Accuracy:100\n",
      "  Time: 12.01s\n",
      "\n",
      "Evaluating 104/105 - Question ID: 104\n",
      "Accuracy:100\n",
      "  Time: 14.32s\n",
      "\n",
      "Evaluating 105/105 - Question ID: 105\n",
      "Accuracy:100\n",
      "  Time: 11.35s\n",
      "\n",
      "============================================================\n",
      "EVALUATION COMPLETE: paperqa_valina_gpt4.1\n",
      "============================================================\n",
      "Backend: gemini\n",
      "Total evaluation time: 1599.89 seconds\n",
      "Successful evaluations: 104/105\n",
      "Success rate: 99.0%\n",
      "\n",
      "Average Scores:\n",
      "  Accuracy: 83.65\n",
      "\n",
      "Final rate limit usage: 1/150 requests, 175/2000000 tokens\n",
      "\n",
      "Results saved to: rag_evaluation_results_gemini/paperqa_valina_gpt4.1_evaluated_20250609_112543.csv\n"
     ]
    }
   ],
   "source": [
    "# Evaluate in smaller batches\n",
    "paperqa_eval = gemini_evaluator.evaluate_single_dataframe(\n",
    "    df=paperqa,\n",
    "    system_name=\"paperqa_valina_gpt4.1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bb0227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4ac0a40",
   "metadata": {},
   "source": [
    "# Eavaluate PaperQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1652d958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EVALUATING: paperqa_modified_gpt4.1 (using gemini backend)\n",
      "============================================================\n",
      "All required columns found\n",
      "Available columns: ['question_id', 'question', 'response', 'answer', 'sources', 'ideal_solution', 'processing_time', 'success', 'error', 'embedding_system']\n",
      "Filtering by success column: 105 successful out of 105 total\n",
      "Rate limit status: 6/150 requests, 851/2000000 tokens\n",
      "\n",
      "Evaluating 1/105 - Question ID: 1\n",
      "Accuracy:100\n",
      "  Time: 9.96s\n",
      "\n",
      "Evaluating 2/105 - Question ID: 2\n",
      "Accuracy:100\n",
      "  Time: 9.01s\n",
      "\n",
      "Evaluating 3/105 - Question ID: 3\n",
      "Accuracy:100\n",
      "  Time: 8.60s\n",
      "\n",
      "Evaluating 4/105 - Question ID: 4\n",
      "Accuracy:100\n",
      "  Time: 13.54s\n",
      "\n",
      "Evaluating 5/105 - Question ID: 5\n",
      "Accuracy:100\n",
      "  Time: 7.43s\n",
      "\n",
      "Evaluating 6/105 - Question ID: 6\n",
      "Accuracy:100\n",
      "  Time: 9.48s\n",
      "\n",
      "Evaluating 7/105 - Question ID: 7\n",
      "Accuracy:100\n",
      "  Time: 12.54s\n",
      "\n",
      "Evaluating 8/105 - Question ID: 8\n",
      "Accuracy:0\n",
      "  Time: 18.23s\n",
      "\n",
      "Evaluating 9/105 - Question ID: 9\n",
      "Accuracy:0\n",
      "  Time: 18.02s\n",
      "\n",
      "Evaluating 10/105 - Question ID: 10\n",
      "Accuracy:100\n",
      "  Time: 11.05s\n",
      "\n",
      "Evaluating 11/105 - Question ID: 11\n",
      "Accuracy:100\n",
      "  Time: 9.93s\n",
      "\n",
      "Evaluating 12/105 - Question ID: 12\n",
      "Accuracy:100\n",
      "  Time: 13.42s\n",
      "\n",
      "Evaluating 13/105 - Question ID: 13\n",
      "Accuracy:100\n",
      "  Time: 13.92s\n",
      "\n",
      "Evaluating 14/105 - Question ID: 14\n",
      "Accuracy:100\n",
      "  Time: 15.49s\n",
      "\n",
      "Evaluating 15/105 - Question ID: 15\n",
      "Accuracy:100\n",
      "  Time: 10.42s\n",
      "\n",
      "Evaluating 16/105 - Question ID: 16\n",
      "Accuracy:100\n",
      "  Time: 13.10s\n",
      "\n",
      "Evaluating 17/105 - Question ID: 17\n",
      "Accuracy:100\n",
      "  Time: 9.42s\n",
      "\n",
      "Evaluating 18/105 - Question ID: 18\n",
      "Accuracy:100\n",
      "  Time: 11.98s\n",
      "\n",
      "Evaluating 19/105 - Question ID: 19\n",
      "Accuracy:100\n",
      "  Time: 8.91s\n",
      "\n",
      "Evaluating 20/105 - Question ID: 20\n",
      "Accuracy:100\n",
      "  Time: 13.40s\n",
      "\n",
      "Evaluating 21/105 - Question ID: 21\n",
      "Accuracy:100\n",
      "  Time: 9.64s\n",
      "\n",
      "Evaluating 22/105 - Question ID: 22\n",
      "Accuracy:100\n",
      "  Time: 8.09s\n",
      "\n",
      "Evaluating 23/105 - Question ID: 23\n",
      "Accuracy:100\n",
      "  Time: 12.38s\n",
      "\n",
      "Evaluating 24/105 - Question ID: 24\n",
      "Accuracy:100\n",
      "  Time: 11.47s\n",
      "\n",
      "Evaluating 25/105 - Question ID: 25\n",
      "Accuracy:0\n",
      "  Time: 12.32s\n",
      "\n",
      "Evaluating 26/105 - Question ID: 26\n",
      "Accuracy:100\n",
      "  Time: 19.73s\n",
      "\n",
      "Evaluating 27/105 - Question ID: 27\n",
      "Accuracy:0\n",
      "  Time: 15.13s\n",
      "\n",
      "Evaluating 28/105 - Question ID: 28\n",
      "Accuracy:0\n",
      "  Time: 19.02s\n",
      "\n",
      "Evaluating 29/105 - Question ID: 29\n",
      "Accuracy:100\n",
      "  Time: 11.72s\n",
      "\n",
      "Evaluating 30/105 - Question ID: 30\n",
      "Accuracy:100\n",
      "  Time: 16.28s\n",
      "\n",
      "Evaluating 31/105 - Question ID: 31\n",
      "Accuracy:100\n",
      "  Time: 10.37s\n",
      "\n",
      "Evaluating 32/105 - Question ID: 32\n",
      "Accuracy:100\n",
      "  Time: 10.45s\n",
      "\n",
      "Evaluating 33/105 - Question ID: 33\n",
      "Accuracy:100\n",
      "  Time: 10.80s\n",
      "\n",
      "Evaluating 34/105 - Question ID: 34\n",
      "Accuracy:0\n",
      "  Time: 14.04s\n",
      "\n",
      "Evaluating 35/105 - Question ID: 35\n",
      "Accuracy:100\n",
      "  Time: 14.33s\n",
      "\n",
      "Evaluating 36/105 - Question ID: 36\n",
      "Accuracy:100\n",
      "  Time: 7.88s\n",
      "\n",
      "Evaluating 37/105 - Question ID: 37\n",
      "Accuracy:100\n",
      "  Time: 5.85s\n",
      "\n",
      "Evaluating 38/105 - Question ID: 38\n",
      "Accuracy:100\n",
      "  Time: 6.87s\n",
      "\n",
      "Evaluating 39/105 - Question ID: 39\n",
      "Accuracy:100\n",
      "  Time: 13.23s\n",
      "\n",
      "Evaluating 40/105 - Question ID: 40\n",
      "Accuracy:100\n",
      "  Time: 10.50s\n",
      "\n",
      "Evaluating 41/105 - Question ID: 41\n",
      "Accuracy:100\n",
      "  Time: 8.81s\n",
      "\n",
      "Evaluating 42/105 - Question ID: 42\n",
      "Accuracy:100\n",
      "  Time: 8.67s\n",
      "\n",
      "Evaluating 43/105 - Question ID: 43\n",
      "Accuracy:100\n",
      "  Time: 11.29s\n",
      "\n",
      "Evaluating 44/105 - Question ID: 44\n",
      "Accuracy:100\n",
      "  Time: 13.91s\n",
      "\n",
      "Evaluating 45/105 - Question ID: 45\n",
      "Accuracy:100\n",
      "  Time: 9.36s\n",
      "\n",
      "Evaluating 46/105 - Question ID: 46\n",
      "Accuracy:0\n",
      "  Time: 7.65s\n",
      "\n",
      "Evaluating 47/105 - Question ID: 47\n",
      "Accuracy:0\n",
      "  Time: 15.42s\n",
      "\n",
      "Evaluating 48/105 - Question ID: 48\n",
      "Accuracy:100\n",
      "  Time: 16.43s\n",
      "\n",
      "Evaluating 49/105 - Question ID: 49\n",
      "Accuracy:100\n",
      "  Time: 8.73s\n",
      "\n",
      "Evaluating 50/105 - Question ID: 50\n",
      "Accuracy:100\n",
      "  Time: 9.96s\n",
      "\n",
      "Evaluating 51/105 - Question ID: 51\n",
      "Accuracy:100\n",
      "  Time: 13.72s\n",
      "\n",
      "Evaluating 52/105 - Question ID: 52\n",
      "Accuracy:100\n",
      "  Time: 14.11s\n",
      "\n",
      "Evaluating 53/105 - Question ID: 53\n",
      "Accuracy:100\n",
      "  Time: 9.39s\n",
      "\n",
      "Evaluating 54/105 - Question ID: 54\n",
      "Accuracy:0\n",
      "  Time: 7.48s\n",
      "\n",
      "Evaluating 55/105 - Question ID: 55\n",
      "Accuracy:100\n",
      "  Time: 14.88s\n",
      "\n",
      "Evaluating 56/105 - Question ID: 56\n",
      "Failed to parse Gemini JSON response: Invalid \\escape: line 3 column 111 (char 137)\n",
      "Raw response: {\n",
      "  \"accuracy_score\": 100,\n",
      "  \"rationale\": \"The generated answer correctly captures the core concepts of the ideal answer. It states that \\Omega_m changes the placement of a galaxy in parameter space and, crucially, that this effect is distinct from astrophysical processes. This aligns perfectly with...\n",
      "  ✗ Failed: JSON parse error: Invalid \\escape: line 3 column 111 (char 137)\n",
      "\n",
      "Evaluating 57/105 - Question ID: 57\n",
      "Accuracy:100\n",
      "  Time: 12.56s\n",
      "\n",
      "Evaluating 58/105 - Question ID: 58\n",
      "Accuracy:100\n",
      "  Time: 11.96s\n",
      "\n",
      "Evaluating 59/105 - Question ID: 59\n",
      "Accuracy:100\n",
      "  Time: 12.64s\n",
      "\n",
      "Evaluating 60/105 - Question ID: 60\n",
      "Accuracy:100\n",
      "  Time: 13.10s\n",
      "\n",
      "Evaluating 61/105 - Question ID: 61\n",
      "Accuracy:100\n",
      "  Time: 10.90s\n",
      "\n",
      "Evaluating 62/105 - Question ID: 62\n",
      "Accuracy:100\n",
      "  Time: 11.00s\n",
      "\n",
      "Evaluating 63/105 - Question ID: 63\n",
      "Accuracy:0\n",
      "  Time: 11.26s\n",
      "\n",
      "Evaluating 64/105 - Question ID: 64\n",
      "Accuracy:100\n",
      "  Time: 10.75s\n",
      "\n",
      "Evaluating 65/105 - Question ID: 65\n",
      "Accuracy:100\n",
      "  Time: 17.76s\n",
      "\n",
      "Evaluating 66/105 - Question ID: 66\n",
      "Accuracy:100\n",
      "  Time: 13.07s\n",
      "\n",
      "Evaluating 67/105 - Question ID: 67\n",
      "Accuracy:100\n",
      "  Time: 9.41s\n",
      "\n",
      "Evaluating 68/105 - Question ID: 68\n",
      "Accuracy:100\n",
      "  Time: 10.86s\n",
      "\n",
      "Evaluating 69/105 - Question ID: 69\n",
      "Accuracy:100\n",
      "  Time: 12.73s\n",
      "\n",
      "Evaluating 70/105 - Question ID: 70\n",
      "Accuracy:100\n",
      "  Time: 14.80s\n",
      "\n",
      "Evaluating 71/105 - Question ID: 71\n",
      "Accuracy:100\n",
      "  Time: 8.91s\n",
      "\n",
      "Evaluating 72/105 - Question ID: 72\n",
      "Accuracy:0\n",
      "  Time: 8.61s\n",
      "\n",
      "Evaluating 73/105 - Question ID: 73\n",
      "Accuracy:0\n",
      "  Time: 8.04s\n",
      "\n",
      "Evaluating 74/105 - Question ID: 74\n",
      "Accuracy:0\n",
      "  Time: 17.85s\n",
      "\n",
      "Evaluating 75/105 - Question ID: 75\n",
      "Accuracy:100\n",
      "  Time: 12.84s\n",
      "\n",
      "Evaluating 76/105 - Question ID: 76\n",
      "Accuracy:100\n",
      "  Time: 16.91s\n",
      "\n",
      "Evaluating 77/105 - Question ID: 77\n",
      "Failed to parse Gemini JSON response: Unterminated string starting at: line 3 column 16 (char 42)\n",
      "Raw response: {\n",
      "  \"accuracy_score\": 100,\n",
      "  \"rationale\": \"The generated answer provides a value for the Hubble constant, H₀ = 73.24 ± 1.74 km s⁻¹ Mpc⁻¹. This is a factually correct value from...\n",
      "  ✗ Failed: JSON parse error: Unterminated string starting at: line 3 column 16 (char 42)\n",
      "\n",
      "Evaluating 78/105 - Question ID: 78\n",
      "Accuracy:100\n",
      "  Time: 11.82s\n",
      "\n",
      "Evaluating 79/105 - Question ID: 79\n",
      "Accuracy:100\n",
      "  Time: 11.59s\n",
      "\n",
      "Evaluating 80/105 - Question ID: 80\n",
      "Accuracy:100\n",
      "  Time: 12.71s\n",
      "\n",
      "Evaluating 81/105 - Question ID: 81\n",
      "Accuracy:100\n",
      "  Time: 15.77s\n",
      "\n",
      "Evaluating 82/105 - Question ID: 82\n",
      "Accuracy:100\n",
      "  Time: 18.94s\n",
      "\n",
      "Evaluating 83/105 - Question ID: 83\n",
      "Accuracy:100\n",
      "  Time: 10.03s\n",
      "\n",
      "Evaluating 84/105 - Question ID: 84\n",
      "Accuracy:100\n",
      "  Time: 14.13s\n",
      "\n",
      "Evaluating 85/105 - Question ID: 85\n",
      "Accuracy:100\n",
      "  Time: 6.76s\n",
      "\n",
      "Evaluating 86/105 - Question ID: 86\n",
      "Accuracy:100\n",
      "  Time: 9.93s\n",
      "\n",
      "Evaluating 87/105 - Question ID: 87\n",
      "Accuracy:0\n",
      "  Time: 7.48s\n",
      "\n",
      "Evaluating 88/105 - Question ID: 88\n",
      "Accuracy:100\n",
      "  Time: 16.79s\n",
      "\n",
      "Evaluating 89/105 - Question ID: 89\n",
      "Accuracy:100\n",
      "  Time: 19.27s\n",
      "\n",
      "Evaluating 90/105 - Question ID: 90\n",
      "Accuracy:100\n",
      "  Time: 9.40s\n",
      "\n",
      "Evaluating 91/105 - Question ID: 91\n",
      "Accuracy:100\n",
      "  Time: 7.78s\n",
      "\n",
      "Evaluating 92/105 - Question ID: 92\n",
      "Accuracy:0\n",
      "  Time: 7.48s\n",
      "\n",
      "Evaluating 93/105 - Question ID: 93\n",
      "Accuracy:0\n",
      "  Time: 15.47s\n",
      "\n",
      "Evaluating 94/105 - Question ID: 94\n",
      "Accuracy:100\n",
      "  Time: 13.30s\n",
      "\n",
      "Evaluating 95/105 - Question ID: 95\n",
      "Accuracy:100\n",
      "  Time: 10.27s\n",
      "\n",
      "Evaluating 96/105 - Question ID: 96\n",
      "Accuracy:100\n",
      "  Time: 9.07s\n",
      "\n",
      "Evaluating 97/105 - Question ID: 97\n",
      "Accuracy:100\n",
      "  Time: 8.09s\n",
      "\n",
      "Evaluating 98/105 - Question ID: 98\n",
      "Accuracy:100\n",
      "  Time: 14.85s\n",
      "\n",
      "Evaluating 99/105 - Question ID: 99\n",
      "Accuracy:100\n",
      "  Time: 12.39s\n",
      "\n",
      "Evaluating 100/105 - Question ID: 100\n",
      "Accuracy:0\n",
      "  Time: 10.99s\n",
      "\n",
      "Evaluating 101/105 - Question ID: 101\n",
      "Accuracy:100\n",
      "  Time: 11.84s\n",
      "\n",
      "Evaluating 102/105 - Question ID: 102\n",
      "Failed to parse Gemini JSON response: Unterminated string starting at: line 3 column 16 (char 40)\n",
      "Raw response: {\n",
      "  \"accuracy_score\": 0,\n",
      "  \"rationale\": \"The generated answer correctly identifies that adding CMB lensing and BAO data (the difference between P-ACT-LB and P-ACT datasets) leads to a weaker constraint...\n",
      "  ✗ Failed: JSON parse error: Unterminated string starting at: line 3 column 16 (char 40)\n",
      "\n",
      "Evaluating 103/105 - Question ID: 103\n",
      "Accuracy:0\n",
      "  Time: 11.10s\n",
      "\n",
      "Evaluating 104/105 - Question ID: 104\n",
      "Accuracy:100\n",
      "  Time: 11.47s\n",
      "\n",
      "Evaluating 105/105 - Question ID: 105\n",
      "Accuracy:100\n",
      "  Time: 6.80s\n",
      "\n",
      "============================================================\n",
      "EVALUATION COMPLETE: paperqa_modified_gpt4.1\n",
      "============================================================\n",
      "Backend: gemini\n",
      "Total evaluation time: 1267.49 seconds\n",
      "Successful evaluations: 102/105\n",
      "Success rate: 97.1%\n",
      "\n",
      "Average Scores:\n",
      "  Accuracy: 82.35\n",
      "\n",
      "Final rate limit usage: 4/150 requests, 924/2000000 tokens\n",
      "\n",
      "Results saved to: rag_evaluation_results_gemini/paperqa_modified_gpt4.1_evaluated_20250608_161808.csv\n"
     ]
    }
   ],
   "source": [
    "paperqa_modified=pd.read_pickle(\"results/paperqa2_gpt4.1_results.pkl\")\n",
    "paperqa_modified_eval = gemini_evaluator.evaluate_single_dataframe(\n",
    "    df=paperqa_modified,\n",
    "    system_name=\"paperqa_modified_gpt4.1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2818ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.90190476190475"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(102*82.35+200)/105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b64b45f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c02e69ab",
   "metadata": {},
   "source": [
    "# OpenAI_Vector_Store_no_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0cb5d7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_vector_no_pdf=pd.read_pickle(\"results/openai_vector_store_results.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fded868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EVALUATING: OpenAI_Vector_Store_md (using gemini backend)\n",
      "============================================================\n",
      "All required columns found\n",
      "Available columns: ['question_id', 'question', 'ideal_solution', 'response', 'answer', 'sources', 'processing_time', 'success', 'error', 'embedding_system']\n",
      "Filtering by success column: 105 successful out of 105 total\n",
      "Rate limit status: 4/150 requests, 924/2000000 tokens\n",
      "\n",
      "Evaluating 1/105 - Question ID: 1\n",
      "Accuracy:100\n",
      "  Time: 8.36s\n",
      "\n",
      "Evaluating 2/105 - Question ID: 2\n",
      "Accuracy:100\n",
      "  Time: 8.36s\n",
      "\n",
      "Evaluating 3/105 - Question ID: 3\n",
      "Accuracy:100\n",
      "  Time: 13.01s\n",
      "\n",
      "Evaluating 4/105 - Question ID: 4\n",
      "Accuracy:100\n",
      "  Time: 11.25s\n",
      "\n",
      "Evaluating 5/105 - Question ID: 5\n",
      "Accuracy:100\n",
      "  Time: 9.87s\n",
      "\n",
      "Evaluating 6/105 - Question ID: 6\n",
      "Accuracy:100\n",
      "  Time: 9.96s\n",
      "\n",
      "Evaluating 7/105 - Question ID: 7\n",
      "Accuracy:100\n",
      "  Time: 15.08s\n",
      "\n",
      "Evaluating 8/105 - Question ID: 8\n",
      "  ✗ Failed: Unknown error after 1 attempts: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.\n",
      "\n",
      "Evaluating 9/105 - Question ID: 9\n",
      "Accuracy:100\n",
      "  Time: 8.19s\n",
      "\n",
      "Evaluating 10/105 - Question ID: 10\n",
      "Accuracy:100\n",
      "  Time: 7.60s\n",
      "\n",
      "Evaluating 11/105 - Question ID: 11\n",
      "Accuracy:100\n",
      "  Time: 9.91s\n",
      "\n",
      "Evaluating 12/105 - Question ID: 12\n",
      "Accuracy:100\n",
      "  Time: 7.70s\n",
      "\n",
      "Evaluating 13/105 - Question ID: 13\n",
      "Accuracy:100\n",
      "  Time: 9.60s\n",
      "\n",
      "Evaluating 14/105 - Question ID: 14\n",
      "Accuracy:0\n",
      "  Time: 14.00s\n",
      "\n",
      "Evaluating 15/105 - Question ID: 15\n",
      "Accuracy:100\n",
      "  Time: 9.81s\n",
      "\n",
      "Evaluating 16/105 - Question ID: 16\n",
      "Accuracy:100\n",
      "  Time: 9.47s\n",
      "\n",
      "Evaluating 17/105 - Question ID: 17\n",
      "Accuracy:100\n",
      "  Time: 10.31s\n",
      "\n",
      "Evaluating 18/105 - Question ID: 18\n",
      "Accuracy:100\n",
      "  Time: 9.32s\n",
      "\n",
      "Evaluating 19/105 - Question ID: 19\n",
      "Accuracy:100\n",
      "  Time: 10.21s\n",
      "\n",
      "Evaluating 20/105 - Question ID: 20\n",
      "Accuracy:0\n",
      "  Time: 16.18s\n",
      "\n",
      "Evaluating 21/105 - Question ID: 21\n",
      "Accuracy:100\n",
      "  Time: 9.16s\n",
      "\n",
      "Evaluating 22/105 - Question ID: 22\n",
      "Accuracy:0\n",
      "  Time: 18.09s\n",
      "\n",
      "Evaluating 23/105 - Question ID: 23\n",
      "Accuracy:100\n",
      "  Time: 9.34s\n",
      "\n",
      "Evaluating 24/105 - Question ID: 24\n",
      "Accuracy:100\n",
      "  Time: 13.42s\n",
      "\n",
      "Evaluating 25/105 - Question ID: 25\n",
      "Accuracy:100\n",
      "  Time: 10.66s\n",
      "\n",
      "Evaluating 26/105 - Question ID: 26\n",
      "Accuracy:100\n",
      "  Time: 14.82s\n",
      "\n",
      "Evaluating 27/105 - Question ID: 27\n",
      "Accuracy:100\n",
      "  Time: 12.47s\n",
      "\n",
      "Evaluating 28/105 - Question ID: 28\n",
      "Accuracy:100\n",
      "  Time: 16.31s\n",
      "\n",
      "Evaluating 29/105 - Question ID: 29\n",
      "Accuracy:100\n",
      "  Time: 9.34s\n",
      "\n",
      "Evaluating 30/105 - Question ID: 30\n",
      "Accuracy:100\n",
      "  Time: 16.35s\n",
      "\n",
      "Evaluating 31/105 - Question ID: 31\n",
      "Accuracy:100\n",
      "  Time: 8.19s\n",
      "\n",
      "Evaluating 32/105 - Question ID: 32\n",
      "Accuracy:100\n",
      "  Time: 14.03s\n",
      "\n",
      "Evaluating 33/105 - Question ID: 33\n",
      "Accuracy:100\n",
      "  Time: 8.51s\n",
      "\n",
      "Evaluating 34/105 - Question ID: 34\n",
      "Accuracy:0\n",
      "  Time: 12.49s\n",
      "\n",
      "Evaluating 35/105 - Question ID: 35\n",
      "Accuracy:100\n",
      "  Time: 10.95s\n",
      "\n",
      "Evaluating 36/105 - Question ID: 36\n",
      "Accuracy:100\n",
      "  Time: 13.11s\n",
      "\n",
      "Evaluating 37/105 - Question ID: 37\n",
      "Accuracy:100\n",
      "  Time: 10.01s\n",
      "\n",
      "Evaluating 38/105 - Question ID: 38\n",
      "Accuracy:100\n",
      "  Time: 11.05s\n",
      "\n",
      "Evaluating 39/105 - Question ID: 39\n",
      "Accuracy:100\n",
      "  Time: 12.48s\n",
      "\n",
      "Evaluating 40/105 - Question ID: 40\n",
      "Accuracy:100\n",
      "  Time: 9.83s\n",
      "\n",
      "Evaluating 41/105 - Question ID: 41\n",
      "Accuracy:100\n",
      "  Time: 9.45s\n",
      "\n",
      "Evaluating 42/105 - Question ID: 42\n",
      "Accuracy:100\n",
      "  Time: 9.11s\n",
      "\n",
      "Evaluating 43/105 - Question ID: 43\n",
      "Accuracy:100\n",
      "  Time: 10.44s\n",
      "\n",
      "Evaluating 44/105 - Question ID: 44\n",
      "Accuracy:100\n",
      "  Time: 11.45s\n",
      "\n",
      "Evaluating 45/105 - Question ID: 45\n",
      "Accuracy:100\n",
      "  Time: 12.69s\n",
      "\n",
      "Evaluating 46/105 - Question ID: 46\n",
      "Accuracy:0\n",
      "  Time: 18.28s\n",
      "\n",
      "Evaluating 47/105 - Question ID: 47\n",
      "Accuracy:100\n",
      "  Time: 7.43s\n",
      "\n",
      "Evaluating 48/105 - Question ID: 48\n",
      "Accuracy:100\n",
      "  Time: 14.53s\n",
      "\n",
      "Evaluating 49/105 - Question ID: 49\n",
      "Accuracy:0\n",
      "  Time: 11.83s\n",
      "\n",
      "Evaluating 50/105 - Question ID: 50\n",
      "Accuracy:100\n",
      "  Time: 9.67s\n",
      "\n",
      "Evaluating 51/105 - Question ID: 51\n",
      "Accuracy:100\n",
      "  Time: 12.59s\n",
      "\n",
      "Evaluating 52/105 - Question ID: 52\n",
      "Accuracy:100\n",
      "  Time: 12.84s\n",
      "\n",
      "Evaluating 53/105 - Question ID: 53\n",
      "Accuracy:100\n",
      "  Time: 14.51s\n",
      "\n",
      "Evaluating 54/105 - Question ID: 54\n",
      "Accuracy:0\n",
      "  Time: 9.41s\n",
      "\n",
      "Evaluating 55/105 - Question ID: 55\n",
      "Accuracy:100\n",
      "  Time: 14.84s\n",
      "\n",
      "Evaluating 56/105 - Question ID: 56\n",
      "Accuracy:100\n",
      "  Time: 11.97s\n",
      "\n",
      "Evaluating 57/105 - Question ID: 57\n",
      "Accuracy:100\n",
      "  Time: 12.18s\n",
      "\n",
      "Evaluating 58/105 - Question ID: 58\n",
      "Accuracy:100\n",
      "  Time: 13.11s\n",
      "\n",
      "Evaluating 59/105 - Question ID: 59\n",
      "Accuracy:100\n",
      "  Time: 13.42s\n",
      "\n",
      "Evaluating 60/105 - Question ID: 60\n",
      "Accuracy:100\n",
      "  Time: 13.27s\n",
      "\n",
      "Evaluating 61/105 - Question ID: 61\n",
      "Accuracy:100\n",
      "  Time: 12.33s\n",
      "\n",
      "Evaluating 62/105 - Question ID: 62\n",
      "Accuracy:100\n",
      "  Time: 11.26s\n",
      "\n",
      "Evaluating 63/105 - Question ID: 63\n",
      "Accuracy:100\n",
      "  Time: 8.49s\n",
      "\n",
      "Evaluating 64/105 - Question ID: 64\n",
      "Accuracy:100\n",
      "  Time: 7.69s\n",
      "\n",
      "Evaluating 65/105 - Question ID: 65\n",
      "Accuracy:100\n",
      "  Time: 11.19s\n",
      "\n",
      "Evaluating 66/105 - Question ID: 66\n",
      "Accuracy:100\n",
      "  Time: 20.75s\n",
      "\n",
      "Evaluating 67/105 - Question ID: 67\n",
      "Accuracy:0\n",
      "  Time: 7.06s\n",
      "\n",
      "Evaluating 68/105 - Question ID: 68\n",
      "Accuracy:100\n",
      "  Time: 9.93s\n",
      "\n",
      "Evaluating 69/105 - Question ID: 69\n",
      "Accuracy:100\n",
      "  Time: 14.57s\n",
      "\n",
      "Evaluating 70/105 - Question ID: 70\n",
      "Accuracy:100\n",
      "  Time: 14.30s\n",
      "\n",
      "Evaluating 71/105 - Question ID: 71\n",
      "Accuracy:100\n",
      "  Time: 9.11s\n",
      "\n",
      "Evaluating 72/105 - Question ID: 72\n",
      "Accuracy:100\n",
      "  Time: 12.05s\n",
      "\n",
      "Evaluating 73/105 - Question ID: 73\n",
      "Accuracy:100\n",
      "  Time: 11.09s\n",
      "\n",
      "Evaluating 74/105 - Question ID: 74\n",
      "Accuracy:100\n",
      "  Time: 16.23s\n",
      "\n",
      "Evaluating 75/105 - Question ID: 75\n",
      "Accuracy:100\n",
      "  Time: 20.64s\n",
      "\n",
      "Evaluating 76/105 - Question ID: 76\n",
      "Accuracy:100\n",
      "  Time: 11.21s\n",
      "\n",
      "Evaluating 77/105 - Question ID: 77\n",
      "Accuracy:100\n",
      "  Time: 12.58s\n",
      "\n",
      "Evaluating 78/105 - Question ID: 78\n",
      "Accuracy:100\n",
      "  Time: 7.43s\n",
      "\n",
      "Evaluating 79/105 - Question ID: 79\n",
      "Accuracy:100\n",
      "  Time: 8.91s\n",
      "\n",
      "Evaluating 80/105 - Question ID: 80\n",
      "Accuracy:100\n",
      "  Time: 11.97s\n",
      "\n",
      "Evaluating 81/105 - Question ID: 81\n",
      "Accuracy:100\n",
      "  Time: 12.30s\n",
      "\n",
      "Evaluating 82/105 - Question ID: 82\n",
      "Accuracy:100\n",
      "  Time: 16.06s\n",
      "\n",
      "Evaluating 83/105 - Question ID: 83\n",
      "Accuracy:100\n",
      "  Time: 6.97s\n",
      "\n",
      "Evaluating 84/105 - Question ID: 84\n",
      "Accuracy:100\n",
      "  Time: 11.88s\n",
      "\n",
      "Evaluating 85/105 - Question ID: 85\n",
      "Accuracy:100\n",
      "  Time: 9.00s\n",
      "\n",
      "Evaluating 86/105 - Question ID: 86\n",
      "Accuracy:100\n",
      "  Time: 9.93s\n",
      "\n",
      "Evaluating 87/105 - Question ID: 87\n",
      "Accuracy:100\n",
      "  Time: 8.31s\n",
      "\n",
      "Evaluating 88/105 - Question ID: 88\n",
      "Accuracy:100\n",
      "  Time: 22.10s\n",
      "\n",
      "Evaluating 89/105 - Question ID: 89\n",
      "Accuracy:100\n",
      "  Time: 14.27s\n",
      "\n",
      "Evaluating 90/105 - Question ID: 90\n",
      "Accuracy:0\n",
      "  Time: 16.66s\n",
      "\n",
      "Evaluating 91/105 - Question ID: 91\n",
      "Accuracy:100\n",
      "  Time: 9.75s\n",
      "\n",
      "Evaluating 92/105 - Question ID: 92\n",
      "Accuracy:100\n",
      "  Time: 10.62s\n",
      "\n",
      "Evaluating 93/105 - Question ID: 93\n",
      "Accuracy:100\n",
      "  Time: 16.14s\n",
      "\n",
      "Evaluating 94/105 - Question ID: 94\n",
      "Accuracy:100\n",
      "  Time: 9.66s\n",
      "\n",
      "Evaluating 95/105 - Question ID: 95\n",
      "Accuracy:100\n",
      "  Time: 7.77s\n",
      "\n",
      "Evaluating 96/105 - Question ID: 96\n",
      "Accuracy:100\n",
      "  Time: 9.72s\n",
      "\n",
      "Evaluating 97/105 - Question ID: 97\n",
      "Accuracy:100\n",
      "  Time: 15.85s\n",
      "\n",
      "Evaluating 98/105 - Question ID: 98\n",
      "Accuracy:100\n",
      "  Time: 14.58s\n",
      "\n",
      "Evaluating 99/105 - Question ID: 99\n",
      "Accuracy:100\n",
      "  Time: 11.26s\n",
      "\n",
      "Evaluating 100/105 - Question ID: 100\n",
      "Accuracy:0\n",
      "  Time: 12.36s\n",
      "\n",
      "Evaluating 101/105 - Question ID: 101\n",
      "Accuracy:100\n",
      "  Time: 10.23s\n",
      "\n",
      "Evaluating 102/105 - Question ID: 102\n",
      "Accuracy:0\n",
      "  Time: 17.35s\n",
      "\n",
      "Evaluating 103/105 - Question ID: 103\n",
      "Accuracy:100\n",
      "  Time: 11.03s\n",
      "\n",
      "Evaluating 104/105 - Question ID: 104\n",
      "Accuracy:100\n",
      "  Time: 18.46s\n",
      "\n",
      "Evaluating 105/105 - Question ID: 105\n",
      "Accuracy:100\n",
      "  Time: 8.20s\n",
      "\n",
      "============================================================\n",
      "EVALUATION COMPLETE: OpenAI_Vector_Store_md\n",
      "============================================================\n",
      "Backend: gemini\n",
      "Total evaluation time: 1256.84 seconds\n",
      "Successful evaluations: 104/105\n",
      "Success rate: 99.0%\n",
      "\n",
      "Average Scores:\n",
      "  Accuracy: 89.42\n",
      "\n",
      "Final rate limit usage: 1/150 requests, 162/2000000 tokens\n",
      "\n",
      "Results saved to: rag_evaluation_results_gemini/openai_vector_store_md_evaluated_20250608_163904.csv\n"
     ]
    }
   ],
   "source": [
    "openai_vector_no_pdf_eval = gemini_evaluator.evaluate_single_dataframe(\n",
    "    df=openai_vector_no_pdf,\n",
    "    system_name=\"OpenAI_Vector_Store_md\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d2d9f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 1 questions...\n",
      "==================================================\n",
      "[Init] Initialized gemini-2.5-pro-preview-06-05 successfully with service account: gemini.json\n",
      "\n",
      "[1/1] Evaluating Question ID: 8\n",
      "[Backoff] Attempt 1/3 failed. Unknown error: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.\n",
      "[Backoff] Sleeping for 25.5 seconds (base: 30s, multiplier: 2.0)\n",
      "  Score: 0/100\n",
      "  Rationale: The generated answer provides a different and less fundamental explanation than the ideal answer. Th...\n"
     ]
    }
   ],
   "source": [
    "qids=[8]\n",
    "missing_question(qids, openai_vector_no_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8bde030d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.56838095238095"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "89.42*104/105"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f183c5da",
   "metadata": {},
   "source": [
    "# OpenAI_Vector_Store_pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56ec000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_vector_df=pd.read_pickle(\"results/openai_pdf_vector_store_results.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4024cc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EVALUATING: OpenAI_Vector_Store (using gemini backend)\n",
      "============================================================\n",
      "All required columns found\n",
      "Available columns: ['question_id', 'question', 'ideal_solution', 'response', 'answer', 'sources', 'processing_time', 'success', 'error', 'embedding_system']\n",
      "Filtering by success column: 105 successful out of 105 total\n",
      "Rate limit status: 1/150 requests, 162/2000000 tokens\n",
      "\n",
      "Evaluating 1/105 - Question ID: 1\n",
      "Accuracy:100\n",
      "  Time: 8.55s\n",
      "\n",
      "Evaluating 2/105 - Question ID: 2\n",
      "Accuracy:100\n",
      "  Time: 7.88s\n",
      "\n",
      "Evaluating 3/105 - Question ID: 3\n",
      "Accuracy:100\n",
      "  Time: 8.80s\n",
      "\n",
      "Evaluating 4/105 - Question ID: 4\n",
      "Accuracy:100\n",
      "  Time: 14.16s\n",
      "\n",
      "Evaluating 5/105 - Question ID: 5\n",
      "Accuracy:100\n",
      "  Time: 9.59s\n",
      "\n",
      "Evaluating 6/105 - Question ID: 6\n",
      "Accuracy:100\n",
      "  Time: 8.80s\n",
      "\n",
      "Evaluating 7/105 - Question ID: 7\n",
      "  ✗ Failed: Unknown error after 1 attempts: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.\n",
      "\n",
      "Evaluating 8/105 - Question ID: 8\n",
      "Accuracy:0\n",
      "  Time: 16.07s\n",
      "\n",
      "Evaluating 9/105 - Question ID: 9\n",
      "Accuracy:100\n",
      "  Time: 10.06s\n",
      "\n",
      "Evaluating 10/105 - Question ID: 10\n",
      "Accuracy:100\n",
      "  Time: 8.27s\n",
      "\n",
      "Evaluating 11/105 - Question ID: 11\n",
      "Accuracy:100\n",
      "  Time: 12.28s\n",
      "\n",
      "Evaluating 12/105 - Question ID: 12\n",
      "Accuracy:100\n",
      "  Time: 10.24s\n",
      "\n",
      "Evaluating 13/105 - Question ID: 13\n",
      "Accuracy:100\n",
      "  Time: 15.15s\n",
      "\n",
      "Evaluating 14/105 - Question ID: 14\n",
      "Accuracy:100\n",
      "  Time: 14.34s\n",
      "\n",
      "Evaluating 15/105 - Question ID: 15\n",
      "Accuracy:100\n",
      "  Time: 9.00s\n",
      "\n",
      "Evaluating 16/105 - Question ID: 16\n",
      "Accuracy:100\n",
      "  Time: 14.13s\n",
      "\n",
      "Evaluating 17/105 - Question ID: 17\n",
      "Accuracy:100\n",
      "  Time: 12.39s\n",
      "\n",
      "Evaluating 18/105 - Question ID: 18\n",
      "Accuracy:100\n",
      "  Time: 9.90s\n",
      "\n",
      "Evaluating 19/105 - Question ID: 19\n",
      "Accuracy:100\n",
      "  Time: 9.76s\n",
      "\n",
      "Evaluating 20/105 - Question ID: 20\n",
      "Accuracy:100\n",
      "  Time: 11.46s\n",
      "\n",
      "Evaluating 21/105 - Question ID: 21\n",
      "Accuracy:100\n",
      "  Time: 9.93s\n",
      "\n",
      "Evaluating 22/105 - Question ID: 22\n",
      "Failed to parse Gemini JSON response: Unterminated string starting at: line 3 column 16 (char 42)\n",
      "Raw response: {\n",
      "  \"accuracy_score\": 100,\n",
      "  \"rationale\": \"The generated answer correctly identifies the core concept from the ideal answer, which is that direct measurements of the Hubble constant (H_0) are in significant tension (well above 2 sigma) with the Planck results....\n",
      "  ✗ Failed: JSON parse error: Unterminated string starting at: line 3 column 16 (char 42)\n",
      "\n",
      "Evaluating 23/105 - Question ID: 23\n",
      "Accuracy:100\n",
      "  Time: 12.51s\n",
      "\n",
      "Evaluating 24/105 - Question ID: 24\n",
      "Accuracy:100\n",
      "  Time: 10.52s\n",
      "\n",
      "Evaluating 25/105 - Question ID: 25\n",
      "Accuracy:100\n",
      "  Time: 8.87s\n",
      "\n",
      "Evaluating 26/105 - Question ID: 26\n",
      "Accuracy:100\n",
      "  Time: 10.51s\n",
      "\n",
      "Evaluating 27/105 - Question ID: 27\n",
      "Accuracy:100\n",
      "  Time: 12.05s\n",
      "\n",
      "Evaluating 28/105 - Question ID: 28\n",
      "Accuracy:100\n",
      "  Time: 10.03s\n",
      "\n",
      "Evaluating 29/105 - Question ID: 29\n",
      "Accuracy:100\n",
      "  Time: 14.65s\n",
      "\n",
      "Evaluating 30/105 - Question ID: 30\n",
      "Accuracy:100\n",
      "  Time: 23.14s\n",
      "\n",
      "Evaluating 31/105 - Question ID: 31\n",
      "Accuracy:100\n",
      "  Time: 7.57s\n",
      "\n",
      "Evaluating 32/105 - Question ID: 32\n",
      "Accuracy:100\n",
      "  Time: 14.57s\n",
      "\n",
      "Evaluating 33/105 - Question ID: 33\n",
      "Accuracy:100\n",
      "  Time: 9.60s\n",
      "\n",
      "Evaluating 34/105 - Question ID: 34\n",
      "Accuracy:100\n",
      "  Time: 9.16s\n",
      "\n",
      "Evaluating 35/105 - Question ID: 35\n",
      "Accuracy:100\n",
      "  Time: 10.07s\n",
      "\n",
      "Evaluating 36/105 - Question ID: 36\n",
      "Accuracy:100\n",
      "  Time: 11.26s\n",
      "\n",
      "Evaluating 37/105 - Question ID: 37\n",
      "Accuracy:100\n",
      "  Time: 6.56s\n",
      "\n",
      "Evaluating 38/105 - Question ID: 38\n",
      "Accuracy:100\n",
      "  Time: 9.80s\n",
      "\n",
      "Evaluating 39/105 - Question ID: 39\n",
      "Accuracy:100\n",
      "  Time: 7.89s\n",
      "\n",
      "Evaluating 40/105 - Question ID: 40\n",
      "Accuracy:100\n",
      "  Time: 10.76s\n",
      "\n",
      "Evaluating 41/105 - Question ID: 41\n",
      "Accuracy:0\n",
      "  Time: 20.87s\n",
      "\n",
      "Evaluating 42/105 - Question ID: 42\n",
      "Accuracy:100\n",
      "  Time: 10.83s\n",
      "\n",
      "Evaluating 43/105 - Question ID: 43\n",
      "Accuracy:100\n",
      "  Time: 9.11s\n",
      "\n",
      "Evaluating 44/105 - Question ID: 44\n",
      "Accuracy:100\n",
      "  Time: 8.52s\n",
      "\n",
      "Evaluating 45/105 - Question ID: 45\n",
      "Accuracy:100\n",
      "  Time: 9.14s\n",
      "\n",
      "Evaluating 46/105 - Question ID: 46\n",
      "Accuracy:0\n",
      "  Time: 10.17s\n",
      "\n",
      "Evaluating 47/105 - Question ID: 47\n",
      "Accuracy:100\n",
      "  Time: 7.71s\n",
      "\n",
      "Evaluating 48/105 - Question ID: 48\n",
      "Accuracy:0\n",
      "  Time: 18.87s\n",
      "\n",
      "Evaluating 49/105 - Question ID: 49\n",
      "Accuracy:100\n",
      "  Time: 9.98s\n",
      "\n",
      "Evaluating 50/105 - Question ID: 50\n",
      "Accuracy:100\n",
      "  Time: 9.09s\n",
      "\n",
      "Evaluating 51/105 - Question ID: 51\n",
      "Accuracy:100\n",
      "  Time: 9.90s\n",
      "\n",
      "Evaluating 52/105 - Question ID: 52\n",
      "Accuracy:100\n",
      "  Time: 12.32s\n",
      "\n",
      "Evaluating 53/105 - Question ID: 53\n",
      "Accuracy:100\n",
      "  Time: 9.54s\n",
      "\n",
      "Evaluating 54/105 - Question ID: 54\n",
      "Accuracy:0\n",
      "  Time: 9.43s\n",
      "\n",
      "Evaluating 55/105 - Question ID: 55\n",
      "Accuracy:100\n",
      "  Time: 11.42s\n",
      "\n",
      "Evaluating 56/105 - Question ID: 56\n",
      "Accuracy:100\n",
      "  Time: 13.31s\n",
      "\n",
      "Evaluating 57/105 - Question ID: 57\n",
      "Accuracy:100\n",
      "  Time: 14.45s\n",
      "\n",
      "Evaluating 58/105 - Question ID: 58\n",
      "Accuracy:100\n",
      "  Time: 13.43s\n",
      "\n",
      "Evaluating 59/105 - Question ID: 59\n",
      "Accuracy:100\n",
      "  Time: 9.49s\n",
      "\n",
      "Evaluating 60/105 - Question ID: 60\n",
      "Accuracy:100\n",
      "  Time: 15.06s\n",
      "\n",
      "Evaluating 61/105 - Question ID: 61\n",
      "Accuracy:100\n",
      "  Time: 7.65s\n",
      "\n",
      "Evaluating 62/105 - Question ID: 62\n",
      "Accuracy:100\n",
      "  Time: 11.11s\n",
      "\n",
      "Evaluating 63/105 - Question ID: 63\n",
      "Accuracy:100\n",
      "  Time: 10.23s\n",
      "\n",
      "Evaluating 64/105 - Question ID: 64\n",
      "Accuracy:100\n",
      "  Time: 7.35s\n",
      "\n",
      "Evaluating 65/105 - Question ID: 65\n",
      "Accuracy:100\n",
      "  Time: 11.57s\n",
      "\n",
      "Evaluating 66/105 - Question ID: 66\n",
      "Accuracy:100\n",
      "  Time: 12.55s\n",
      "\n",
      "Evaluating 67/105 - Question ID: 67\n",
      "Accuracy:100\n",
      "  Time: 10.06s\n",
      "\n",
      "Evaluating 68/105 - Question ID: 68\n",
      "Accuracy:100\n",
      "  Time: 9.93s\n",
      "\n",
      "Evaluating 69/105 - Question ID: 69\n",
      "Accuracy:100\n",
      "  Time: 10.68s\n",
      "\n",
      "Evaluating 70/105 - Question ID: 70\n",
      "Accuracy:100\n",
      "  Time: 8.19s\n",
      "\n",
      "Evaluating 71/105 - Question ID: 71\n",
      "Accuracy:100\n",
      "  Time: 7.78s\n",
      "\n",
      "Evaluating 72/105 - Question ID: 72\n",
      "Accuracy:100\n",
      "  Time: 10.33s\n",
      "\n",
      "Evaluating 73/105 - Question ID: 73\n",
      "Accuracy:100\n",
      "  Time: 11.93s\n",
      "\n",
      "Evaluating 74/105 - Question ID: 74\n",
      "Accuracy:100\n",
      "  Time: 8.71s\n",
      "\n",
      "Evaluating 75/105 - Question ID: 75\n",
      "Accuracy:0\n",
      "  Time: 12.28s\n",
      "\n",
      "Evaluating 76/105 - Question ID: 76\n",
      "Accuracy:100\n",
      "  Time: 6.91s\n",
      "\n",
      "Evaluating 77/105 - Question ID: 77\n",
      "Accuracy:100\n",
      "  Time: 14.58s\n",
      "\n",
      "Evaluating 78/105 - Question ID: 78\n",
      "Accuracy:100\n",
      "  Time: 9.27s\n",
      "\n",
      "Evaluating 79/105 - Question ID: 79\n",
      "Accuracy:100\n",
      "  Time: 8.58s\n",
      "\n",
      "Evaluating 80/105 - Question ID: 80\n",
      "Accuracy:100\n",
      "  Time: 7.52s\n",
      "\n",
      "Evaluating 81/105 - Question ID: 81\n",
      "Accuracy:100\n",
      "  Time: 10.03s\n",
      "\n",
      "Evaluating 82/105 - Question ID: 82\n",
      "Accuracy:100\n",
      "  Time: 14.03s\n",
      "\n",
      "Evaluating 83/105 - Question ID: 83\n",
      "Accuracy:100\n",
      "  Time: 9.33s\n",
      "\n",
      "Evaluating 84/105 - Question ID: 84\n",
      "Accuracy:100\n",
      "  Time: 14.33s\n",
      "\n",
      "Evaluating 85/105 - Question ID: 85\n",
      "Accuracy:100\n",
      "  Time: 7.15s\n",
      "\n",
      "Evaluating 86/105 - Question ID: 86\n",
      "Accuracy:100\n",
      "  Time: 6.20s\n",
      "\n",
      "Evaluating 87/105 - Question ID: 87\n",
      "Accuracy:100\n",
      "  Time: 8.62s\n",
      "\n",
      "Evaluating 88/105 - Question ID: 88\n",
      "Accuracy:100\n",
      "  Time: 13.20s\n",
      "\n",
      "Evaluating 89/105 - Question ID: 89\n",
      "Accuracy:100\n",
      "  Time: 14.03s\n",
      "\n",
      "Evaluating 90/105 - Question ID: 90\n",
      "Accuracy:100\n",
      "  Time: 7.70s\n",
      "\n",
      "Evaluating 91/105 - Question ID: 91\n",
      "Accuracy:100\n",
      "  Time: 12.57s\n",
      "\n",
      "Evaluating 92/105 - Question ID: 92\n",
      "Accuracy:100\n",
      "  Time: 9.63s\n",
      "\n",
      "Evaluating 93/105 - Question ID: 93\n",
      "Accuracy:100\n",
      "  Time: 8.51s\n",
      "\n",
      "Evaluating 94/105 - Question ID: 94\n",
      "Accuracy:0\n",
      "  Time: 8.59s\n",
      "\n",
      "Evaluating 95/105 - Question ID: 95\n",
      "Accuracy:100\n",
      "  Time: 8.41s\n",
      "\n",
      "Evaluating 96/105 - Question ID: 96\n",
      "Accuracy:100\n",
      "  Time: 7.86s\n",
      "\n",
      "Evaluating 97/105 - Question ID: 97\n",
      "Accuracy:100\n",
      "  Time: 9.22s\n",
      "\n",
      "Evaluating 98/105 - Question ID: 98\n",
      "Accuracy:100\n",
      "  Time: 9.07s\n",
      "\n",
      "Evaluating 99/105 - Question ID: 99\n",
      "Accuracy:100\n",
      "  Time: 8.23s\n",
      "\n",
      "Evaluating 100/105 - Question ID: 100\n",
      "Accuracy:0\n",
      "  Time: 13.85s\n",
      "\n",
      "Evaluating 101/105 - Question ID: 101\n",
      "Accuracy:100\n",
      "  Time: 10.57s\n",
      "\n",
      "Evaluating 102/105 - Question ID: 102\n",
      "Accuracy:0\n",
      "  Time: 13.47s\n",
      "\n",
      "Evaluating 103/105 - Question ID: 103\n",
      "Accuracy:100\n",
      "  Time: 11.75s\n",
      "\n",
      "Evaluating 104/105 - Question ID: 104\n",
      "Accuracy:100\n",
      "  Time: 16.63s\n",
      "\n",
      "Evaluating 105/105 - Question ID: 105\n",
      "Accuracy:100\n",
      "  Time: 9.30s\n",
      "\n",
      "============================================================\n",
      "EVALUATION COMPLETE: OpenAI_Vector_Store\n",
      "============================================================\n",
      "Backend: gemini\n",
      "Total evaluation time: 1157.59 seconds\n",
      "Successful evaluations: 103/105\n",
      "Success rate: 98.1%\n",
      "\n",
      "Average Scores:\n",
      "  Accuracy: 91.26\n",
      "\n",
      "Final rate limit usage: 1/150 requests, 153/2000000 tokens\n",
      "\n",
      "Results saved to: rag_evaluation_results_gemini/openai_vector_store_evaluated_20250608_165822.csv\n"
     ]
    }
   ],
   "source": [
    "openai_vector_df_eval = gemini_evaluator.evaluate_single_dataframe(\n",
    "    df=openai_vector_df,\n",
    "    system_name=\"OpenAI_Vector_Store\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d3cf53fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 1 questions...\n",
      "==================================================\n",
      "[Init] Initialized gemini-2.5-pro-preview-06-05 successfully with service account: gemini.json\n",
      "\n",
      "[1/1] Evaluating Question ID: 22\n",
      "  Score: 0/100\n",
      "  Rationale: The generated answer directly contradicts the ideal answer. The ideal answer states that 'Only the d...\n"
     ]
    }
   ],
   "source": [
    "qids=[22]\n",
    "missing_question(qids, openai_vector_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d0668a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.47409523809525"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(91.26*103+100)/105"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03e8ad4",
   "metadata": {},
   "source": [
    "# OpenAi Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f1ca67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_embedding=pd.read_pickle(\"results/openai_embedding_results_final.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee9124ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EVALUATING: OpenAI_embedding (using gemini backend)\n",
      "============================================================\n",
      "All required columns found\n",
      "Available columns: ['question_id', 'question', 'response', 'ideal_solution', 'answer', 'sources', 'processing_time', 'success', 'error', 'embedding_system']\n",
      "Filtering by success column: 105 successful out of 105 total\n",
      "Rate limit status: 1/150 requests, 153/2000000 tokens\n",
      "\n",
      "Evaluating 1/105 - Question ID: 1\n",
      "Accuracy:100\n",
      "  Time: 7.74s\n",
      "\n",
      "Evaluating 2/105 - Question ID: 2\n",
      "Accuracy:100\n",
      "  Time: 7.86s\n",
      "\n",
      "Evaluating 3/105 - Question ID: 3\n",
      "Accuracy:100\n",
      "  Time: 7.61s\n",
      "\n",
      "Evaluating 4/105 - Question ID: 4\n",
      "Accuracy:100\n",
      "  Time: 8.29s\n",
      "\n",
      "Evaluating 5/105 - Question ID: 5\n",
      "Accuracy:100\n",
      "  Time: 8.76s\n",
      "\n",
      "Evaluating 6/105 - Question ID: 6\n",
      "Accuracy:100\n",
      "  Time: 10.28s\n",
      "\n",
      "Evaluating 7/105 - Question ID: 7\n",
      "Accuracy:100\n",
      "  Time: 11.98s\n",
      "\n",
      "Evaluating 8/105 - Question ID: 8\n",
      "Accuracy:100\n",
      "  Time: 17.63s\n",
      "\n",
      "Evaluating 9/105 - Question ID: 9\n",
      "Accuracy:100\n",
      "  Time: 13.68s\n",
      "\n",
      "Evaluating 10/105 - Question ID: 10\n",
      "Accuracy:100\n",
      "  Time: 28.90s\n",
      "\n",
      "Evaluating 11/105 - Question ID: 11\n",
      "Failed to parse Gemini JSON response: Unterminated string starting at: line 3 column 16 (char 40)\n",
      "Raw response: {\n",
      "  \"accuracy_score\": 0,\n",
      "  \"rationale\": \"The user's question asks for \\\"parameter constraints\\\" (plural...\n",
      "  ✗ Failed: JSON parse error: Unterminated string starting at: line 3 column 16 (char 40)\n",
      "\n",
      "Evaluating 12/105 - Question ID: 12\n",
      "Accuracy:100\n",
      "  Time: 10.98s\n",
      "\n",
      "Evaluating 13/105 - Question ID: 13\n",
      "Accuracy:100\n",
      "  Time: 14.80s\n",
      "\n",
      "Evaluating 14/105 - Question ID: 14\n",
      "Accuracy:100\n",
      "  Time: 12.52s\n",
      "\n",
      "Evaluating 15/105 - Question ID: 15\n",
      "Accuracy:100\n",
      "  Time: 9.90s\n",
      "\n",
      "Evaluating 16/105 - Question ID: 16\n",
      "Accuracy:100\n",
      "  Time: 10.55s\n",
      "\n",
      "Evaluating 17/105 - Question ID: 17\n",
      "Accuracy:100\n",
      "  Time: 9.23s\n",
      "\n",
      "Evaluating 18/105 - Question ID: 18\n",
      "Accuracy:100\n",
      "  Time: 11.79s\n",
      "\n",
      "Evaluating 19/105 - Question ID: 19\n",
      "Accuracy:100\n",
      "  Time: 7.22s\n",
      "\n",
      "Evaluating 20/105 - Question ID: 20\n",
      "Accuracy:0\n",
      "  Time: 15.72s\n",
      "\n",
      "Evaluating 21/105 - Question ID: 21\n",
      "Accuracy:100\n",
      "  Time: 15.38s\n",
      "\n",
      "Evaluating 22/105 - Question ID: 22\n",
      "Accuracy:0\n",
      "  Time: 25.52s\n",
      "\n",
      "Evaluating 23/105 - Question ID: 23\n",
      "Accuracy:100\n",
      "  Time: 11.53s\n",
      "\n",
      "Evaluating 24/105 - Question ID: 24\n",
      "Accuracy:100\n",
      "  Time: 12.37s\n",
      "\n",
      "Evaluating 25/105 - Question ID: 25\n",
      "Accuracy:100\n",
      "  Time: 13.99s\n",
      "\n",
      "Evaluating 26/105 - Question ID: 26\n",
      "Accuracy:100\n",
      "  Time: 10.94s\n",
      "\n",
      "Evaluating 27/105 - Question ID: 27\n",
      "Accuracy:100\n",
      "  Time: 11.71s\n",
      "\n",
      "Evaluating 28/105 - Question ID: 28\n",
      "Accuracy:0\n",
      "  Time: 17.55s\n",
      "\n",
      "Evaluating 29/105 - Question ID: 29\n",
      "Accuracy:100\n",
      "  Time: 11.72s\n",
      "\n",
      "Evaluating 30/105 - Question ID: 30\n",
      "Accuracy:100\n",
      "  Time: 15.94s\n",
      "\n",
      "Evaluating 31/105 - Question ID: 31\n",
      "Accuracy:100\n",
      "  Time: 8.30s\n",
      "\n",
      "Evaluating 32/105 - Question ID: 32\n",
      "Accuracy:100\n",
      "  Time: 11.33s\n",
      "\n",
      "Evaluating 33/105 - Question ID: 33\n",
      "Accuracy:100\n",
      "  Time: 10.38s\n",
      "\n",
      "Evaluating 34/105 - Question ID: 34\n",
      "Accuracy:0\n",
      "  Time: 12.19s\n",
      "\n",
      "Evaluating 35/105 - Question ID: 35\n",
      "Accuracy:100\n",
      "  Time: 10.96s\n",
      "\n",
      "Evaluating 36/105 - Question ID: 36\n",
      "Accuracy:100\n",
      "  Time: 7.77s\n",
      "\n",
      "Evaluating 37/105 - Question ID: 37\n",
      "Accuracy:100\n",
      "  Time: 11.00s\n",
      "\n",
      "Evaluating 38/105 - Question ID: 38\n",
      "Accuracy:100\n",
      "  Time: 10.71s\n",
      "\n",
      "Evaluating 39/105 - Question ID: 39\n",
      "Accuracy:100\n",
      "  Time: 14.64s\n",
      "\n",
      "Evaluating 40/105 - Question ID: 40\n",
      "Accuracy:100\n",
      "  Time: 7.17s\n",
      "\n",
      "Evaluating 41/105 - Question ID: 41\n",
      "Accuracy:100\n",
      "  Time: 8.74s\n",
      "\n",
      "Evaluating 42/105 - Question ID: 42\n",
      "Accuracy:100\n",
      "  Time: 10.91s\n",
      "\n",
      "Evaluating 43/105 - Question ID: 43\n",
      "Accuracy:100\n",
      "  Time: 9.99s\n",
      "\n",
      "Evaluating 44/105 - Question ID: 44\n",
      "Accuracy:100\n",
      "  Time: 13.57s\n",
      "\n",
      "Evaluating 45/105 - Question ID: 45\n",
      "Accuracy:100\n",
      "  Time: 11.30s\n",
      "\n",
      "Evaluating 46/105 - Question ID: 46\n",
      "Accuracy:0\n",
      "  Time: 7.65s\n",
      "\n",
      "Evaluating 47/105 - Question ID: 47\n",
      "Accuracy:100\n",
      "  Time: 5.51s\n",
      "\n",
      "Evaluating 48/105 - Question ID: 48\n",
      "Accuracy:100\n",
      "  Time: 11.56s\n",
      "\n",
      "Evaluating 49/105 - Question ID: 49\n",
      "Accuracy:100\n",
      "  Time: 11.56s\n",
      "\n",
      "Evaluating 50/105 - Question ID: 50\n",
      "Accuracy:100\n",
      "  Time: 11.68s\n",
      "\n",
      "Evaluating 51/105 - Question ID: 51\n",
      "Accuracy:100\n",
      "  Time: 8.87s\n",
      "\n",
      "Evaluating 52/105 - Question ID: 52\n",
      "Accuracy:100\n",
      "  Time: 14.95s\n",
      "\n",
      "Evaluating 53/105 - Question ID: 53\n",
      "Accuracy:100\n",
      "  Time: 9.96s\n",
      "\n",
      "Evaluating 54/105 - Question ID: 54\n",
      "Accuracy:0\n",
      "  Time: 7.75s\n",
      "\n",
      "Evaluating 55/105 - Question ID: 55\n",
      "Accuracy:100\n",
      "  Time: 13.75s\n",
      "\n",
      "Evaluating 56/105 - Question ID: 56\n",
      "Accuracy:100\n",
      "  Time: 11.20s\n",
      "\n",
      "Evaluating 57/105 - Question ID: 57\n",
      "Accuracy:100\n",
      "  Time: 11.75s\n",
      "\n",
      "Evaluating 58/105 - Question ID: 58\n",
      "Accuracy:100\n",
      "  Time: 13.24s\n",
      "\n",
      "Evaluating 59/105 - Question ID: 59\n",
      "Accuracy:100\n",
      "  Time: 7.07s\n",
      "\n",
      "Evaluating 60/105 - Question ID: 60\n",
      "Accuracy:100\n",
      "  Time: 9.86s\n",
      "\n",
      "Evaluating 61/105 - Question ID: 61\n",
      "Accuracy:100\n",
      "  Time: 6.36s\n",
      "\n",
      "Evaluating 62/105 - Question ID: 62\n",
      "Accuracy:100\n",
      "  Time: 10.06s\n",
      "\n",
      "Evaluating 63/105 - Question ID: 63\n",
      "Accuracy:100\n",
      "  Time: 9.27s\n",
      "\n",
      "Evaluating 64/105 - Question ID: 64\n",
      "Accuracy:100\n",
      "  Time: 8.17s\n",
      "\n",
      "Evaluating 65/105 - Question ID: 65\n",
      "Accuracy:100\n",
      "  Time: 7.99s\n",
      "\n",
      "Evaluating 66/105 - Question ID: 66\n",
      "Accuracy:100\n",
      "  Time: 8.71s\n",
      "\n",
      "Evaluating 67/105 - Question ID: 67\n",
      "Accuracy:100\n",
      "  Time: 10.12s\n",
      "\n",
      "Evaluating 68/105 - Question ID: 68\n",
      "Accuracy:100\n",
      "  Time: 8.63s\n",
      "\n",
      "Evaluating 69/105 - Question ID: 69\n",
      "Accuracy:0\n",
      "  Time: 7.09s\n",
      "\n",
      "Evaluating 70/105 - Question ID: 70\n",
      "Accuracy:0\n",
      "  Time: 9.65s\n",
      "\n",
      "Evaluating 71/105 - Question ID: 71\n",
      "Accuracy:100\n",
      "  Time: 12.34s\n",
      "\n",
      "Evaluating 72/105 - Question ID: 72\n",
      "Accuracy:100\n",
      "  Time: 11.11s\n",
      "\n",
      "Evaluating 73/105 - Question ID: 73\n",
      "Accuracy:100\n",
      "  Time: 6.24s\n",
      "\n",
      "Evaluating 74/105 - Question ID: 74\n",
      "Accuracy:100\n",
      "  Time: 11.67s\n",
      "\n",
      "Evaluating 75/105 - Question ID: 75\n",
      "Accuracy:100\n",
      "  Time: 16.79s\n",
      "\n",
      "Evaluating 76/105 - Question ID: 76\n",
      "Accuracy:100\n",
      "  Time: 19.74s\n",
      "\n",
      "Evaluating 77/105 - Question ID: 77\n",
      "Accuracy:100\n",
      "  Time: 12.00s\n",
      "\n",
      "Evaluating 78/105 - Question ID: 78\n",
      "Accuracy:100\n",
      "  Time: 9.45s\n",
      "\n",
      "Evaluating 79/105 - Question ID: 79\n",
      "Accuracy:100\n",
      "  Time: 8.95s\n",
      "\n",
      "Evaluating 80/105 - Question ID: 80\n",
      "Accuracy:100\n",
      "  Time: 10.61s\n",
      "\n",
      "Evaluating 81/105 - Question ID: 81\n",
      "Accuracy:100\n",
      "  Time: 13.87s\n",
      "\n",
      "Evaluating 82/105 - Question ID: 82\n",
      "Accuracy:100\n",
      "  Time: 15.25s\n",
      "\n",
      "Evaluating 83/105 - Question ID: 83\n",
      "Accuracy:100\n",
      "  Time: 8.13s\n",
      "\n",
      "Evaluating 84/105 - Question ID: 84\n",
      "Accuracy:100\n",
      "  Time: 10.60s\n",
      "\n",
      "Evaluating 85/105 - Question ID: 85\n",
      "Accuracy:100\n",
      "  Time: 7.14s\n",
      "\n",
      "Evaluating 86/105 - Question ID: 86\n",
      "Accuracy:100\n",
      "  Time: 7.41s\n",
      "\n",
      "Evaluating 87/105 - Question ID: 87\n",
      "Accuracy:100\n",
      "  Time: 7.98s\n",
      "\n",
      "Evaluating 88/105 - Question ID: 88\n",
      "Accuracy:100\n",
      "  Time: 16.72s\n",
      "\n",
      "Evaluating 89/105 - Question ID: 89\n",
      "Accuracy:100\n",
      "  Time: 9.89s\n",
      "\n",
      "Evaluating 90/105 - Question ID: 90\n",
      "Accuracy:100\n",
      "  Time: 8.48s\n",
      "\n",
      "Evaluating 91/105 - Question ID: 91\n",
      "Accuracy:100\n",
      "  Time: 7.18s\n",
      "\n",
      "Evaluating 92/105 - Question ID: 92\n",
      "Accuracy:100\n",
      "  Time: 11.29s\n",
      "\n",
      "Evaluating 93/105 - Question ID: 93\n",
      "Accuracy:100\n",
      "  Time: 10.82s\n",
      "\n",
      "Evaluating 94/105 - Question ID: 94\n",
      "Accuracy:100\n",
      "  Time: 8.69s\n",
      "\n",
      "Evaluating 95/105 - Question ID: 95\n",
      "Accuracy:100\n",
      "  Time: 10.80s\n",
      "\n",
      "Evaluating 96/105 - Question ID: 96\n",
      "Accuracy:100\n",
      "  Time: 8.76s\n",
      "\n",
      "Evaluating 97/105 - Question ID: 97\n",
      "Accuracy:100\n",
      "  Time: 11.30s\n",
      "\n",
      "Evaluating 98/105 - Question ID: 98\n",
      "Accuracy:100\n",
      "  Time: 10.19s\n",
      "\n",
      "Evaluating 99/105 - Question ID: 99\n",
      "Accuracy:100\n",
      "  Time: 6.11s\n",
      "\n",
      "Evaluating 100/105 - Question ID: 100\n",
      "Accuracy:100\n",
      "  Time: 7.46s\n",
      "\n",
      "Evaluating 101/105 - Question ID: 101\n",
      "Accuracy:100\n",
      "  Time: 9.31s\n",
      "\n",
      "Evaluating 102/105 - Question ID: 102\n",
      "Accuracy:0\n",
      "  Time: 12.50s\n",
      "\n",
      "Evaluating 103/105 - Question ID: 103\n",
      "Accuracy:100\n",
      "  Time: 13.35s\n",
      "\n",
      "Evaluating 104/105 - Question ID: 104\n",
      "Accuracy:100\n",
      "  Time: 21.50s\n",
      "\n",
      "Evaluating 105/105 - Question ID: 105\n",
      "Accuracy:100\n",
      "  Time: 11.49s\n",
      "\n",
      "============================================================\n",
      "EVALUATION COMPLETE: OpenAI_embedding\n",
      "============================================================\n",
      "Backend: gemini\n",
      "Total evaluation time: 1182.94 seconds\n",
      "Successful evaluations: 104/105\n",
      "Success rate: 99.0%\n",
      "\n",
      "Average Scores:\n",
      "  Accuracy: 91.35\n",
      "\n",
      "Final rate limit usage: 1/150 requests, 146/2000000 tokens\n",
      "\n",
      "Results saved to: rag_evaluation_results_gemini/openai_embedding_evaluated_20250608_171805.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gemini_no_openai_embedding_eval = gemini_evaluator.evaluate_single_dataframe(\n",
    "    df=openai_embedding,\n",
    "    system_name=\"OpenAI_embedding\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd2dc84e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.47999999999999"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "91.35*104/105"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
