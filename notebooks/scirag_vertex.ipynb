{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe52bc73-45d5-4bf5-8e83-749ea3fa3e4e",
   "metadata": {
    "include-cell-in-app": true
   },
   "source": [
    "## Create Corpus From Markdown (ONLY TBD BY BORIS)\n",
    "\n",
    "- Create a Google Cloud Bucket. \n",
    "- Specify its name in the config.py (there is a variable there).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
<<<<<<< HEAD
   "id": "c5aa9f7e-777c-4f86-ba76-a1c92e2a6ea4",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": [
    "# from scirag.config import upload_markdown_files_to_gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35351101-fac8-4177-82d9-8abb919592cb",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": [
    "# upload_markdown_files_to_gcs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106721f3-c97f-4710-9317-2b042f155bf7",
   "metadata": {
    "include-cell-in-app": true
   },
   "source": [
    "This uploaded the local files to the google cloud storage (bucket). \n",
    "\n",
    "We can now create the vector DB. "
=======
   "id": "279dfdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"gemini.json\"\n",
    "\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if api_key is None:\n",
    "    raise RuntimeError(\"Please set the OPENAI_API_KEY \")"
>>>>>>> April
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
   "id": "69375b12-27ec-4c63-92c0-4a401c823f30",
   "metadata": {
    "include-cell-in-app": true
   },
=======
   "execution_count": 2,
   "id": "0769985e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scirag.config import upload_markdown_files_to_gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bfa1085",
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload_markdown_files_to_gcs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c48b79b9-297d-48db-8be0-71aa21a918a7",
   "metadata": {},
>>>>>>> April
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/pybtex/plugin/__init__.py:26: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing RAG Corpora:\n",
      "--- Corpus: corpus ---\n",
      "  Name (Resource Path): projects/camels-453517/locations/us-central1/ragCorpora/5181391371289755648\n",
      "  Display Name: corpus\n",
      "  Create Time: 2025-06-04 22:37:28\n",
      "  Update Time: 2025-06-04 22:37:28\n",
<<<<<<< HEAD
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from scirag import SciRagVertexAI\n",
    "\n",
    "scirag = SciRagVertexAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d51b6b14-4c42-4b80-ad1d-2faf783f40df",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": [
    "# scirag.create_vector_db() ## this only creates the corpus... the files have to be imported manually. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb10bd9-ecfe-4178-9b05-f181d5b8954d",
   "metadata": {
    "include-cell-in-app": true
   },
   "source": [
    "## Delete corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "356a1cef-e9fb-470b-90d1-37a8962d5805",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# scirag.delete_vector_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b209010f-a991-4989-bff3-3c981f8ee9de",
   "metadata": {
    "include-cell-in-app": true
   },
   "source": [
    "## Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c48b79b9-297d-48db-8be0-71aa21a918a7",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing RAG Corpora:\n",
      "--- Corpus: corpus ---\n",
      "  Name (Resource Path): projects/camels-453517/locations/us-central1/ragCorpora/5181391371289755648\n",
      "  Display Name: corpus\n",
      "  Create Time: 2025-06-04 22:37:28\n",
      "  Update Time: 2025-06-04 22:37:28\n",
=======
>>>>>>> April
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from scirag import SciRagVertexAI, SciRagDataSet\n",
    "\n",
    "scirag = SciRagVertexAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bb4bd44-75fa-461d-80ed-d05ffbfdc6bd",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": [
    "dataset = SciRagDataSet()\n",
    "qa = dataset.load_dataset()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 6,
>>>>>>> April
   "id": "4eb3d883-c868-4100-8531-5274a533c66c",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "CPU times: user 80.9 ms, sys: 6.62 ms, total: 87.5 ms\n",
      "Wall time: 5.16 s\n"
=======
      "\n",
      "--- Vertex AI Usage Summary ---\n",
      "Model: gemini-2.5-flash-preview-05-20\n",
      "Input tokens: 22\n",
      "Output tokens: 101\n",
      "Total tokens: 123\n",
      "Cost: $0.000357\n",
      "Input cost: $0.000003\n",
      "Output cost: $0.000354 (thinking)\n",
      "--- End Summary ---\n",
      "\n",
      "\n",
      "--- Vertex AI Usage Summary ---\n",
      "                         Model      Cost  Prompt Tokens  Completion Tokens  Total Tokens\n",
      "gemini-2.5-flash-preview-05-20 $0.000357             22                101           123\n",
      "--- End Summary ---\n",
      "\n",
      "CPU times: user 64.2 ms, sys: 14.7 ms, total: 78.9 ms\n",
      "Wall time: 5.58 s\n"
>>>>>>> April
     ]
    }
   ],
   "source": [
    "%%time\n",
    "qid = 4\n",
    "question = qa['question'].iloc[qid]\n",
    "response = scirag.get_response(question)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 7,
>>>>>>> April
   "id": "8985d7e5-ca31-40e6-9271-645a87dd4fd6",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "Question: How large is the impact of beam window functions on the 2018 spectra in the baseline Plik likelihood?\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(scirag.enhanced_query(question)))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 8,
>>>>>>> April
   "id": "0951d28c-c9c2-4a77-bd46-57c7c24c853e",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Answer**:\n",
       "\n",
<<<<<<< HEAD
       "The impact of beam window functions on the 2018 spectra in the baseline Plik likelihood is small, approximately 0.1% at \\ell=2000. This is because the 2018 release applies beam window functions calculated for the specific sky fraction retained at each frequency, unlike the 2015 approach which assumed the same average sky fraction.\n",
=======
       "The impact of beam window functions on the 2018 spectra in the baseline Plik likelihood is small, approximately 0.1% at \\(\\ell=2000\\). This is due to the application of beam window functions calculated for the specific sky fraction retained at each frequency in the new release, unlike the 2015 approach which assumed the same average sky fraction.\n",
>>>>>>> April
       "\n",
       "**Sources**:\n",
       "\n",
       "1807.06209v4.md\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 9,
>>>>>>> April
   "id": "ac062658-69e3-47ab-9b42-380df42694fc",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'approximately 0.1% at l=2000'"
      ]
     },
<<<<<<< HEAD
     "execution_count": 6,
=======
     "execution_count": 9,
>>>>>>> April
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa['ideal'].iloc[qid]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 10,
>>>>>>> April
   "id": "b2682619-ddb5-4145-9019-1dec4fdb2abe",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p6; sec2.2.1'"
      ]
     },
<<<<<<< HEAD
     "execution_count": 7,
=======
     "execution_count": 10,
>>>>>>> April
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa['Location'].iloc[qid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef5c8477",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SciRagVertexAI._log_usage_and_cost() missing 3 required positional arguments: 'input_tokens', 'output_tokens', and 'total_cost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m total_cost \u001b[38;5;241m=\u001b[39m \u001b[43mscirag\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_usage_and_cost\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: SciRagVertexAI._log_usage_and_cost() missing 3 required positional arguments: 'input_tokens', 'output_tokens', and 'total_cost'"
     ]
    }
   ],
   "source": [
    "total_cost = scirag._log_usage_and_cost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e524b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_cost': 0.0,\n",
       " 'total_calls': 0,\n",
       " 'total_input_tokens': 0,\n",
       " 'total_output_tokens': 0,\n",
       " 'total_tokens': 0,\n",
       " 'average_cost_per_call': 0.0,\n",
       " 'model': 'gemini-2.5-flash-preview-05-20'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_cost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
